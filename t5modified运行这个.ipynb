{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1: Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T14:22:24.002539100Z",
     "start_time": "2024-04-23T14:22:17.028008600Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments, AutoModelForPreTraining, pipeline\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2: Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T14:22:32.932984900Z",
     "start_time": "2024-04-23T14:22:23.992541300Z"
    }
   },
   "outputs": [],
   "source": [
    "#ds = load_dataset(\"cnn_dailymail\", \"1.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T07:25:45.308280600Z",
     "start_time": "2024-04-24T07:25:34.387959400Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = load_dataset(\"cnn_dailymail\", \"1.0.0\", split='train[:90%]')\n",
    "val_ds = load_dataset(\"cnn_dailymail\", \"1.0.0\", split='train[90%:]')\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['article', 'highlights', 'id'],\n    num_rows: 28711\n})"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.shuffle(seed=42)\n",
    "val_ds.shuffle(seed=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T07:26:40.129509Z",
     "start_time": "2024-04-24T07:26:40.095508800Z"
    }
   },
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3: Analyze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T07:26:53.331368500Z",
     "start_time": "2024-04-24T07:26:53.325367700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T14:22:39.702982100Z",
     "start_time": "2024-04-23T14:22:33.086981400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded...\n"
     ]
    }
   ],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-small\", max_length=1024)\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google-t5/t5-small\", max_seq_len=1024)\n",
    "#model = T5ForConditionalGeneration.from_pretrained(\"google-t5/t5-small\", max_memory = 1024)\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"./summary/last-checkpoint-1536\", max_memory = 1024)\n",
    "print(\"Model weights loaded...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T07:29:38.345315200Z",
     "start_time": "2024-04-24T07:29:38.307314700Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_func(examples):\n",
    "    contents = ['Generate summary: \\n' + e for e in examples['article']]\n",
    "    inputs = tokenizer(contents, max_length=1024, truncation=True)\n",
    "    labels = tokenizer(text_target=examples['highlights'], max_length=64, truncation=True)\n",
    "    inputs['labels'] = labels['input_ids']\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T14:22:44.959980400Z",
     "start_time": "2024-04-23T14:22:39.713988400Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_ds = ds.map(process_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T14:22:45.022982800Z",
     "start_time": "2024-04-23T14:22:44.961981800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Generate summary: LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won\\'t cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don\\'t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don\\'t think I\\'ll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he\\'ll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I\\'ll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe\\'s earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say \\'kid star goes off the rails,\\'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films. Watch I-Reporter give her review of Potter\\'s latest ». There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer\\'s \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he\\'s legally an adult: \"I just think I\\'m going to be more sort of fair game,\" he told Reuters. E-mail to a friend. Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.</s>'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_ds['train'][0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T14:22:45.024983600Z",
     "start_time": "2024-04-23T14:22:45.008982300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday. Young actor says he has no plans to fritter his cash away. Radcliffe's earnings from first five Potter films have been held in trust fund.</s>\""
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_ds['train'][0]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\"Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday . Young actor says he has no plans to fritter his cash away . Radcliffe's earnings from first five Potter films have been held in trust fund .\""
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]['highlights']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T14:22:45.077982100Z",
     "start_time": "2024-04-23T14:22:45.024983600Z"
    }
   },
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step4: Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T14:22:45.079982600Z",
     "start_time": "2024-04-23T14:22:45.038983100Z"
    }
   },
   "outputs": [],
   "source": [
    "#model = AutoModelForSeq2SeqLM.from_pretrained(\"google-t5/t5-small\", max_length=1024)\n",
    "#model = AutoModelForSeq2SeqLM.from_pretrained(\"./summary/checkpoint-1536\", max_length = 1024)\n",
    "#print(\"Model weights loaded...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step5: Create evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T14:22:45.125981900Z",
     "start_time": "2024-04-23T14:22:45.054984400Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rouge import Rouge\n",
    "\n",
    "rouge = Rouge()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T14:22:45.128981100Z",
     "start_time": "2024-04-23T14:22:45.071982200Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metric(evalPred):\n",
    "    preds, labels = evalPred\n",
    "    decode_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decode_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    decode_preds = [\" \".join(p) for p in decode_preds]\n",
    "    decode_labels = [\" \".join(p) for p in decode_labels]\n",
    "    scores = rouge.get_scores(decode_preds, decode_labels, avg=True)\n",
    "    return {\n",
    "        \"rouge-1\": scores['rouge-1']['f'],\n",
    "        \"rouge-2\": scores['rouge-2']['f'],\n",
    "        \"rouge-l\": scores['rouge-l']['f']\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step6: Set training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T14:22:45.193981200Z",
     "start_time": "2024-04-23T14:22:45.086984800Z"
    }
   },
   "outputs": [],
   "source": [
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./summary\",\n",
    "    learning_rate=3e-4,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=8,\n",
    "    warmup_steps=128,\n",
    "    logging_steps=512,\n",
    "    logging_dir=\"./logging\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=512,\n",
    "    save_total_limit=3,     # save the last 3 model\n",
    "    metric_for_best_model=\"rouge-l\",\n",
    "    predict_with_generate=True,  # must set True\n",
    "    #load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step7: Create trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T14:22:45.385981800Z",
     "start_time": "2024-04-23T14:22:45.196981600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\ML2\\lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    args=args,\n",
    "    model=model,\n",
    "    train_dataset=tokenized_ds['train'],\n",
    "    eval_dataset=tokenized_ds['test'],\n",
    "    compute_metrics=compute_metric,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step8: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T06:54:10.149637700Z",
     "start_time": "2024-04-23T14:22:45.480982200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='513' max='13458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  513/13458 31:01 < 13:06:06, 0.27 it/s, Epoch 0.11/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1025' max='13458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1025/13458 1:20:44 < 16:21:12, 0.21 it/s, Epoch 0.23/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>512</td>\n      <td>1.743200</td>\n      <td>1.724787</td>\n      <td>0.771811</td>\n      <td>0.411786</td>\n      <td>0.691962</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1537' max='13458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1537/13458 2:06:12 < 16:20:05, 0.20 it/s, Epoch 0.34/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>512</td>\n      <td>1.743200</td>\n      <td>1.724787</td>\n      <td>0.771811</td>\n      <td>0.411786</td>\n      <td>0.691962</td>\n    </tr>\n    <tr>\n      <td>1024</td>\n      <td>1.731100</td>\n      <td>1.722753</td>\n      <td>0.772798</td>\n      <td>0.413633</td>\n      <td>0.691759</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2049' max='13458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 2049/13458 2:49:39 < 15:45:34, 0.20 it/s, Epoch 0.46/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>512</td>\n      <td>1.743200</td>\n      <td>1.724787</td>\n      <td>0.771811</td>\n      <td>0.411786</td>\n      <td>0.691962</td>\n    </tr>\n    <tr>\n      <td>1024</td>\n      <td>1.731100</td>\n      <td>1.722753</td>\n      <td>0.772798</td>\n      <td>0.413633</td>\n      <td>0.691759</td>\n    </tr>\n    <tr>\n      <td>1536</td>\n      <td>1.733300</td>\n      <td>1.709278</td>\n      <td>0.772665</td>\n      <td>0.414348</td>\n      <td>0.693385</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2561' max='13458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 2561/13458 3:33:17 < 15:08:15, 0.20 it/s, Epoch 0.57/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>512</td>\n      <td>1.743200</td>\n      <td>1.724787</td>\n      <td>0.771811</td>\n      <td>0.411786</td>\n      <td>0.691962</td>\n    </tr>\n    <tr>\n      <td>1024</td>\n      <td>1.731100</td>\n      <td>1.722753</td>\n      <td>0.772798</td>\n      <td>0.413633</td>\n      <td>0.691759</td>\n    </tr>\n    <tr>\n      <td>1536</td>\n      <td>1.733300</td>\n      <td>1.709278</td>\n      <td>0.772665</td>\n      <td>0.414348</td>\n      <td>0.693385</td>\n    </tr>\n    <tr>\n      <td>2048</td>\n      <td>1.855800</td>\n      <td>1.680838</td>\n      <td>0.773619</td>\n      <td>0.416598</td>\n      <td>0.695329</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='3073' max='13458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 3073/13458 4:19:24 < 14:37:14, 0.20 it/s, Epoch 0.68/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>512</td>\n      <td>1.743200</td>\n      <td>1.724787</td>\n      <td>0.771811</td>\n      <td>0.411786</td>\n      <td>0.691962</td>\n    </tr>\n    <tr>\n      <td>1024</td>\n      <td>1.731100</td>\n      <td>1.722753</td>\n      <td>0.772798</td>\n      <td>0.413633</td>\n      <td>0.691759</td>\n    </tr>\n    <tr>\n      <td>1536</td>\n      <td>1.733300</td>\n      <td>1.709278</td>\n      <td>0.772665</td>\n      <td>0.414348</td>\n      <td>0.693385</td>\n    </tr>\n    <tr>\n      <td>2048</td>\n      <td>1.855800</td>\n      <td>1.680838</td>\n      <td>0.773619</td>\n      <td>0.416598</td>\n      <td>0.695329</td>\n    </tr>\n    <tr>\n      <td>2560</td>\n      <td>1.842700</td>\n      <td>1.661814</td>\n      <td>0.773028</td>\n      <td>0.413879</td>\n      <td>0.693893</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='3585' max='13458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 3585/13458 5:08:28 < 14:09:59, 0.19 it/s, Epoch 0.80/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>512</td>\n      <td>1.743200</td>\n      <td>1.724787</td>\n      <td>0.771811</td>\n      <td>0.411786</td>\n      <td>0.691962</td>\n    </tr>\n    <tr>\n      <td>1024</td>\n      <td>1.731100</td>\n      <td>1.722753</td>\n      <td>0.772798</td>\n      <td>0.413633</td>\n      <td>0.691759</td>\n    </tr>\n    <tr>\n      <td>1536</td>\n      <td>1.733300</td>\n      <td>1.709278</td>\n      <td>0.772665</td>\n      <td>0.414348</td>\n      <td>0.693385</td>\n    </tr>\n    <tr>\n      <td>2048</td>\n      <td>1.855800</td>\n      <td>1.680838</td>\n      <td>0.773619</td>\n      <td>0.416598</td>\n      <td>0.695329</td>\n    </tr>\n    <tr>\n      <td>2560</td>\n      <td>1.842700</td>\n      <td>1.661814</td>\n      <td>0.773028</td>\n      <td>0.413879</td>\n      <td>0.693893</td>\n    </tr>\n    <tr>\n      <td>3072</td>\n      <td>1.827000</td>\n      <td>1.664096</td>\n      <td>0.772125</td>\n      <td>0.411808</td>\n      <td>0.693255</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='4097' max='13458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 4097/13458 5:55:55 < 13:33:37, 0.19 it/s, Epoch 0.91/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>512</td>\n      <td>1.743200</td>\n      <td>1.724787</td>\n      <td>0.771811</td>\n      <td>0.411786</td>\n      <td>0.691962</td>\n    </tr>\n    <tr>\n      <td>1024</td>\n      <td>1.731100</td>\n      <td>1.722753</td>\n      <td>0.772798</td>\n      <td>0.413633</td>\n      <td>0.691759</td>\n    </tr>\n    <tr>\n      <td>1536</td>\n      <td>1.733300</td>\n      <td>1.709278</td>\n      <td>0.772665</td>\n      <td>0.414348</td>\n      <td>0.693385</td>\n    </tr>\n    <tr>\n      <td>2048</td>\n      <td>1.855800</td>\n      <td>1.680838</td>\n      <td>0.773619</td>\n      <td>0.416598</td>\n      <td>0.695329</td>\n    </tr>\n    <tr>\n      <td>2560</td>\n      <td>1.842700</td>\n      <td>1.661814</td>\n      <td>0.773028</td>\n      <td>0.413879</td>\n      <td>0.693893</td>\n    </tr>\n    <tr>\n      <td>3072</td>\n      <td>1.827000</td>\n      <td>1.664096</td>\n      <td>0.772125</td>\n      <td>0.411808</td>\n      <td>0.693255</td>\n    </tr>\n    <tr>\n      <td>3584</td>\n      <td>1.828500</td>\n      <td>1.653124</td>\n      <td>0.772310</td>\n      <td>0.414298</td>\n      <td>0.693539</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='4609' max='13458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 4609/13458 6:42:47 < 12:53:40, 0.19 it/s, Epoch 1.03/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>512</td>\n      <td>1.743200</td>\n      <td>1.724787</td>\n      <td>0.771811</td>\n      <td>0.411786</td>\n      <td>0.691962</td>\n    </tr>\n    <tr>\n      <td>1024</td>\n      <td>1.731100</td>\n      <td>1.722753</td>\n      <td>0.772798</td>\n      <td>0.413633</td>\n      <td>0.691759</td>\n    </tr>\n    <tr>\n      <td>1536</td>\n      <td>1.733300</td>\n      <td>1.709278</td>\n      <td>0.772665</td>\n      <td>0.414348</td>\n      <td>0.693385</td>\n    </tr>\n    <tr>\n      <td>2048</td>\n      <td>1.855800</td>\n      <td>1.680838</td>\n      <td>0.773619</td>\n      <td>0.416598</td>\n      <td>0.695329</td>\n    </tr>\n    <tr>\n      <td>2560</td>\n      <td>1.842700</td>\n      <td>1.661814</td>\n      <td>0.773028</td>\n      <td>0.413879</td>\n      <td>0.693893</td>\n    </tr>\n    <tr>\n      <td>3072</td>\n      <td>1.827000</td>\n      <td>1.664096</td>\n      <td>0.772125</td>\n      <td>0.411808</td>\n      <td>0.693255</td>\n    </tr>\n    <tr>\n      <td>3584</td>\n      <td>1.828500</td>\n      <td>1.653124</td>\n      <td>0.772310</td>\n      <td>0.414298</td>\n      <td>0.693539</td>\n    </tr>\n    <tr>\n      <td>4096</td>\n      <td>1.819300</td>\n      <td>1.656115</td>\n      <td>0.771975</td>\n      <td>0.413020</td>\n      <td>0.693362</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='5121' max='13458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 5121/13458 7:28:42 < 12:10:47, 0.19 it/s, Epoch 1.14/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>512</td>\n      <td>1.743200</td>\n      <td>1.724787</td>\n      <td>0.771811</td>\n      <td>0.411786</td>\n      <td>0.691962</td>\n    </tr>\n    <tr>\n      <td>1024</td>\n      <td>1.731100</td>\n      <td>1.722753</td>\n      <td>0.772798</td>\n      <td>0.413633</td>\n      <td>0.691759</td>\n    </tr>\n    <tr>\n      <td>1536</td>\n      <td>1.733300</td>\n      <td>1.709278</td>\n      <td>0.772665</td>\n      <td>0.414348</td>\n      <td>0.693385</td>\n    </tr>\n    <tr>\n      <td>2048</td>\n      <td>1.855800</td>\n      <td>1.680838</td>\n      <td>0.773619</td>\n      <td>0.416598</td>\n      <td>0.695329</td>\n    </tr>\n    <tr>\n      <td>2560</td>\n      <td>1.842700</td>\n      <td>1.661814</td>\n      <td>0.773028</td>\n      <td>0.413879</td>\n      <td>0.693893</td>\n    </tr>\n    <tr>\n      <td>3072</td>\n      <td>1.827000</td>\n      <td>1.664096</td>\n      <td>0.772125</td>\n      <td>0.411808</td>\n      <td>0.693255</td>\n    </tr>\n    <tr>\n      <td>3584</td>\n      <td>1.828500</td>\n      <td>1.653124</td>\n      <td>0.772310</td>\n      <td>0.414298</td>\n      <td>0.693539</td>\n    </tr>\n    <tr>\n      <td>4096</td>\n      <td>1.819300</td>\n      <td>1.656115</td>\n      <td>0.771975</td>\n      <td>0.413020</td>\n      <td>0.693362</td>\n    </tr>\n    <tr>\n      <td>4608</td>\n      <td>1.805900</td>\n      <td>1.660652</td>\n      <td>0.772301</td>\n      <td>0.412626</td>\n      <td>0.693388</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='5633' max='13458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 5633/13458 8:13:28 < 11:25:45, 0.19 it/s, Epoch 1.26/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>512</td>\n      <td>1.743200</td>\n      <td>1.724787</td>\n      <td>0.771811</td>\n      <td>0.411786</td>\n      <td>0.691962</td>\n    </tr>\n    <tr>\n      <td>1024</td>\n      <td>1.731100</td>\n      <td>1.722753</td>\n      <td>0.772798</td>\n      <td>0.413633</td>\n      <td>0.691759</td>\n    </tr>\n    <tr>\n      <td>1536</td>\n      <td>1.733300</td>\n      <td>1.709278</td>\n      <td>0.772665</td>\n      <td>0.414348</td>\n      <td>0.693385</td>\n    </tr>\n    <tr>\n      <td>2048</td>\n      <td>1.855800</td>\n      <td>1.680838</td>\n      <td>0.773619</td>\n      <td>0.416598</td>\n      <td>0.695329</td>\n    </tr>\n    <tr>\n      <td>2560</td>\n      <td>1.842700</td>\n      <td>1.661814</td>\n      <td>0.773028</td>\n      <td>0.413879</td>\n      <td>0.693893</td>\n    </tr>\n    <tr>\n      <td>3072</td>\n      <td>1.827000</td>\n      <td>1.664096</td>\n      <td>0.772125</td>\n      <td>0.411808</td>\n      <td>0.693255</td>\n    </tr>\n    <tr>\n      <td>3584</td>\n      <td>1.828500</td>\n      <td>1.653124</td>\n      <td>0.772310</td>\n      <td>0.414298</td>\n      <td>0.693539</td>\n    </tr>\n    <tr>\n      <td>4096</td>\n      <td>1.819300</td>\n      <td>1.656115</td>\n      <td>0.771975</td>\n      <td>0.413020</td>\n      <td>0.693362</td>\n    </tr>\n    <tr>\n      <td>4608</td>\n      <td>1.805900</td>\n      <td>1.660652</td>\n      <td>0.772301</td>\n      <td>0.412626</td>\n      <td>0.693388</td>\n    </tr>\n    <tr>\n      <td>5120</td>\n      <td>1.778000</td>\n      <td>1.644493</td>\n      <td>0.772808</td>\n      <td>0.413753</td>\n      <td>0.694583</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='6145' max='13458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 6145/13458 8:57:36 < 10:39:59, 0.19 it/s, Epoch 1.37/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>512</td>\n      <td>1.743200</td>\n      <td>1.724787</td>\n      <td>0.771811</td>\n      <td>0.411786</td>\n      <td>0.691962</td>\n    </tr>\n    <tr>\n      <td>1024</td>\n      <td>1.731100</td>\n      <td>1.722753</td>\n      <td>0.772798</td>\n      <td>0.413633</td>\n      <td>0.691759</td>\n    </tr>\n    <tr>\n      <td>1536</td>\n      <td>1.733300</td>\n      <td>1.709278</td>\n      <td>0.772665</td>\n      <td>0.414348</td>\n      <td>0.693385</td>\n    </tr>\n    <tr>\n      <td>2048</td>\n      <td>1.855800</td>\n      <td>1.680838</td>\n      <td>0.773619</td>\n      <td>0.416598</td>\n      <td>0.695329</td>\n    </tr>\n    <tr>\n      <td>2560</td>\n      <td>1.842700</td>\n      <td>1.661814</td>\n      <td>0.773028</td>\n      <td>0.413879</td>\n      <td>0.693893</td>\n    </tr>\n    <tr>\n      <td>3072</td>\n      <td>1.827000</td>\n      <td>1.664096</td>\n      <td>0.772125</td>\n      <td>0.411808</td>\n      <td>0.693255</td>\n    </tr>\n    <tr>\n      <td>3584</td>\n      <td>1.828500</td>\n      <td>1.653124</td>\n      <td>0.772310</td>\n      <td>0.414298</td>\n      <td>0.693539</td>\n    </tr>\n    <tr>\n      <td>4096</td>\n      <td>1.819300</td>\n      <td>1.656115</td>\n      <td>0.771975</td>\n      <td>0.413020</td>\n      <td>0.693362</td>\n    </tr>\n    <tr>\n      <td>4608</td>\n      <td>1.805900</td>\n      <td>1.660652</td>\n      <td>0.772301</td>\n      <td>0.412626</td>\n      <td>0.693388</td>\n    </tr>\n    <tr>\n      <td>5120</td>\n      <td>1.778000</td>\n      <td>1.644493</td>\n      <td>0.772808</td>\n      <td>0.413753</td>\n      <td>0.694583</td>\n    </tr>\n    <tr>\n      <td>5632</td>\n      <td>1.770800</td>\n      <td>1.640512</td>\n      <td>0.772375</td>\n      <td>0.412301</td>\n      <td>0.692956</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='6657' max='13458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 6657/13458 9:41:46 < 9:54:32, 0.19 it/s, Epoch 1.48/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>512</td>\n      <td>1.743200</td>\n      <td>1.724787</td>\n      <td>0.771811</td>\n      <td>0.411786</td>\n      <td>0.691962</td>\n    </tr>\n    <tr>\n      <td>1024</td>\n      <td>1.731100</td>\n      <td>1.722753</td>\n      <td>0.772798</td>\n      <td>0.413633</td>\n      <td>0.691759</td>\n    </tr>\n    <tr>\n      <td>1536</td>\n      <td>1.733300</td>\n      <td>1.709278</td>\n      <td>0.772665</td>\n      <td>0.414348</td>\n      <td>0.693385</td>\n    </tr>\n    <tr>\n      <td>2048</td>\n      <td>1.855800</td>\n      <td>1.680838</td>\n      <td>0.773619</td>\n      <td>0.416598</td>\n      <td>0.695329</td>\n    </tr>\n    <tr>\n      <td>2560</td>\n      <td>1.842700</td>\n      <td>1.661814</td>\n      <td>0.773028</td>\n      <td>0.413879</td>\n      <td>0.693893</td>\n    </tr>\n    <tr>\n      <td>3072</td>\n      <td>1.827000</td>\n      <td>1.664096</td>\n      <td>0.772125</td>\n      <td>0.411808</td>\n      <td>0.693255</td>\n    </tr>\n    <tr>\n      <td>3584</td>\n      <td>1.828500</td>\n      <td>1.653124</td>\n      <td>0.772310</td>\n      <td>0.414298</td>\n      <td>0.693539</td>\n    </tr>\n    <tr>\n      <td>4096</td>\n      <td>1.819300</td>\n      <td>1.656115</td>\n      <td>0.771975</td>\n      <td>0.413020</td>\n      <td>0.693362</td>\n    </tr>\n    <tr>\n      <td>4608</td>\n      <td>1.805900</td>\n      <td>1.660652</td>\n      <td>0.772301</td>\n      <td>0.412626</td>\n      <td>0.693388</td>\n    </tr>\n    <tr>\n      <td>5120</td>\n      <td>1.778000</td>\n      <td>1.644493</td>\n      <td>0.772808</td>\n      <td>0.413753</td>\n      <td>0.694583</td>\n    </tr>\n    <tr>\n      <td>5632</td>\n      <td>1.770800</td>\n      <td>1.640512</td>\n      <td>0.772375</td>\n      <td>0.412301</td>\n      <td>0.692956</td>\n    </tr>\n    <tr>\n      <td>6144</td>\n      <td>1.767100</td>\n      <td>1.636624</td>\n      <td>0.772884</td>\n      <td>0.414658</td>\n      <td>0.694682</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='7169' max='13458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 7169/13458 10:26:41 < 9:09:54, 0.19 it/s, Epoch 1.60/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>512</td>\n      <td>1.743200</td>\n      <td>1.724787</td>\n      <td>0.771811</td>\n      <td>0.411786</td>\n      <td>0.691962</td>\n    </tr>\n    <tr>\n      <td>1024</td>\n      <td>1.731100</td>\n      <td>1.722753</td>\n      <td>0.772798</td>\n      <td>0.413633</td>\n      <td>0.691759</td>\n    </tr>\n    <tr>\n      <td>1536</td>\n      <td>1.733300</td>\n      <td>1.709278</td>\n      <td>0.772665</td>\n      <td>0.414348</td>\n      <td>0.693385</td>\n    </tr>\n    <tr>\n      <td>2048</td>\n      <td>1.855800</td>\n      <td>1.680838</td>\n      <td>0.773619</td>\n      <td>0.416598</td>\n      <td>0.695329</td>\n    </tr>\n    <tr>\n      <td>2560</td>\n      <td>1.842700</td>\n      <td>1.661814</td>\n      <td>0.773028</td>\n      <td>0.413879</td>\n      <td>0.693893</td>\n    </tr>\n    <tr>\n      <td>3072</td>\n      <td>1.827000</td>\n      <td>1.664096</td>\n      <td>0.772125</td>\n      <td>0.411808</td>\n      <td>0.693255</td>\n    </tr>\n    <tr>\n      <td>3584</td>\n      <td>1.828500</td>\n      <td>1.653124</td>\n      <td>0.772310</td>\n      <td>0.414298</td>\n      <td>0.693539</td>\n    </tr>\n    <tr>\n      <td>4096</td>\n      <td>1.819300</td>\n      <td>1.656115</td>\n      <td>0.771975</td>\n      <td>0.413020</td>\n      <td>0.693362</td>\n    </tr>\n    <tr>\n      <td>4608</td>\n      <td>1.805900</td>\n      <td>1.660652</td>\n      <td>0.772301</td>\n      <td>0.412626</td>\n      <td>0.693388</td>\n    </tr>\n    <tr>\n      <td>5120</td>\n      <td>1.778000</td>\n      <td>1.644493</td>\n      <td>0.772808</td>\n      <td>0.413753</td>\n      <td>0.694583</td>\n    </tr>\n    <tr>\n      <td>5632</td>\n      <td>1.770800</td>\n      <td>1.640512</td>\n      <td>0.772375</td>\n      <td>0.412301</td>\n      <td>0.692956</td>\n    </tr>\n    <tr>\n      <td>6144</td>\n      <td>1.767100</td>\n      <td>1.636624</td>\n      <td>0.772884</td>\n      <td>0.414658</td>\n      <td>0.694682</td>\n    </tr>\n    <tr>\n      <td>6656</td>\n      <td>1.772200</td>\n      <td>1.638855</td>\n      <td>0.773756</td>\n      <td>0.414890</td>\n      <td>0.694503</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='7681' max='13458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 7681/13458 11:11:25 < 8:25:07, 0.19 it/s, Epoch 1.71/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>512</td>\n      <td>1.743200</td>\n      <td>1.724787</td>\n      <td>0.771811</td>\n      <td>0.411786</td>\n      <td>0.691962</td>\n    </tr>\n    <tr>\n      <td>1024</td>\n      <td>1.731100</td>\n      <td>1.722753</td>\n      <td>0.772798</td>\n      <td>0.413633</td>\n      <td>0.691759</td>\n    </tr>\n    <tr>\n      <td>1536</td>\n      <td>1.733300</td>\n      <td>1.709278</td>\n      <td>0.772665</td>\n      <td>0.414348</td>\n      <td>0.693385</td>\n    </tr>\n    <tr>\n      <td>2048</td>\n      <td>1.855800</td>\n      <td>1.680838</td>\n      <td>0.773619</td>\n      <td>0.416598</td>\n      <td>0.695329</td>\n    </tr>\n    <tr>\n      <td>2560</td>\n      <td>1.842700</td>\n      <td>1.661814</td>\n      <td>0.773028</td>\n      <td>0.413879</td>\n      <td>0.693893</td>\n    </tr>\n    <tr>\n      <td>3072</td>\n      <td>1.827000</td>\n      <td>1.664096</td>\n      <td>0.772125</td>\n      <td>0.411808</td>\n      <td>0.693255</td>\n    </tr>\n    <tr>\n      <td>3584</td>\n      <td>1.828500</td>\n      <td>1.653124</td>\n      <td>0.772310</td>\n      <td>0.414298</td>\n      <td>0.693539</td>\n    </tr>\n    <tr>\n      <td>4096</td>\n      <td>1.819300</td>\n      <td>1.656115</td>\n      <td>0.771975</td>\n      <td>0.413020</td>\n      <td>0.693362</td>\n    </tr>\n    <tr>\n      <td>4608</td>\n      <td>1.805900</td>\n      <td>1.660652</td>\n      <td>0.772301</td>\n      <td>0.412626</td>\n      <td>0.693388</td>\n    </tr>\n    <tr>\n      <td>5120</td>\n      <td>1.778000</td>\n      <td>1.644493</td>\n      <td>0.772808</td>\n      <td>0.413753</td>\n      <td>0.694583</td>\n    </tr>\n    <tr>\n      <td>5632</td>\n      <td>1.770800</td>\n      <td>1.640512</td>\n      <td>0.772375</td>\n      <td>0.412301</td>\n      <td>0.692956</td>\n    </tr>\n    <tr>\n      <td>6144</td>\n      <td>1.767100</td>\n      <td>1.636624</td>\n      <td>0.772884</td>\n      <td>0.414658</td>\n      <td>0.694682</td>\n    </tr>\n    <tr>\n      <td>6656</td>\n      <td>1.772200</td>\n      <td>1.638855</td>\n      <td>0.773756</td>\n      <td>0.414890</td>\n      <td>0.694503</td>\n    </tr>\n    <tr>\n      <td>7168</td>\n      <td>1.766600</td>\n      <td>1.632809</td>\n      <td>0.773255</td>\n      <td>0.414565</td>\n      <td>0.693579</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='8193' max='13458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 8193/13458 12:00:43 < 7:43:16, 0.19 it/s, Epoch 1.83/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>512</td>\n      <td>1.743200</td>\n      <td>1.724787</td>\n      <td>0.771811</td>\n      <td>0.411786</td>\n      <td>0.691962</td>\n    </tr>\n    <tr>\n      <td>1024</td>\n      <td>1.731100</td>\n      <td>1.722753</td>\n      <td>0.772798</td>\n      <td>0.413633</td>\n      <td>0.691759</td>\n    </tr>\n    <tr>\n      <td>1536</td>\n      <td>1.733300</td>\n      <td>1.709278</td>\n      <td>0.772665</td>\n      <td>0.414348</td>\n      <td>0.693385</td>\n    </tr>\n    <tr>\n      <td>2048</td>\n      <td>1.855800</td>\n      <td>1.680838</td>\n      <td>0.773619</td>\n      <td>0.416598</td>\n      <td>0.695329</td>\n    </tr>\n    <tr>\n      <td>2560</td>\n      <td>1.842700</td>\n      <td>1.661814</td>\n      <td>0.773028</td>\n      <td>0.413879</td>\n      <td>0.693893</td>\n    </tr>\n    <tr>\n      <td>3072</td>\n      <td>1.827000</td>\n      <td>1.664096</td>\n      <td>0.772125</td>\n      <td>0.411808</td>\n      <td>0.693255</td>\n    </tr>\n    <tr>\n      <td>3584</td>\n      <td>1.828500</td>\n      <td>1.653124</td>\n      <td>0.772310</td>\n      <td>0.414298</td>\n      <td>0.693539</td>\n    </tr>\n    <tr>\n      <td>4096</td>\n      <td>1.819300</td>\n      <td>1.656115</td>\n      <td>0.771975</td>\n      <td>0.413020</td>\n      <td>0.693362</td>\n    </tr>\n    <tr>\n      <td>4608</td>\n      <td>1.805900</td>\n      <td>1.660652</td>\n      <td>0.772301</td>\n      <td>0.412626</td>\n      <td>0.693388</td>\n    </tr>\n    <tr>\n      <td>5120</td>\n      <td>1.778000</td>\n      <td>1.644493</td>\n      <td>0.772808</td>\n      <td>0.413753</td>\n      <td>0.694583</td>\n    </tr>\n    <tr>\n      <td>5632</td>\n      <td>1.770800</td>\n      <td>1.640512</td>\n      <td>0.772375</td>\n      <td>0.412301</td>\n      <td>0.692956</td>\n    </tr>\n    <tr>\n      <td>6144</td>\n      <td>1.767100</td>\n      <td>1.636624</td>\n      <td>0.772884</td>\n      <td>0.414658</td>\n      <td>0.694682</td>\n    </tr>\n    <tr>\n      <td>6656</td>\n      <td>1.772200</td>\n      <td>1.638855</td>\n      <td>0.773756</td>\n      <td>0.414890</td>\n      <td>0.694503</td>\n    </tr>\n    <tr>\n      <td>7168</td>\n      <td>1.766600</td>\n      <td>1.632809</td>\n      <td>0.773255</td>\n      <td>0.414565</td>\n      <td>0.693579</td>\n    </tr>\n    <tr>\n      <td>7680</td>\n      <td>1.765500</td>\n      <td>1.636061</td>\n      <td>0.773124</td>\n      <td>0.414600</td>\n      <td>0.694203</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='8705' max='13458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 8705/13458 12:49:21 < 7:00:10, 0.19 it/s, Epoch 1.94/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>512</td>\n      <td>1.743200</td>\n      <td>1.724787</td>\n      <td>0.771811</td>\n      <td>0.411786</td>\n      <td>0.691962</td>\n    </tr>\n    <tr>\n      <td>1024</td>\n      <td>1.731100</td>\n      <td>1.722753</td>\n      <td>0.772798</td>\n      <td>0.413633</td>\n      <td>0.691759</td>\n    </tr>\n    <tr>\n      <td>1536</td>\n      <td>1.733300</td>\n      <td>1.709278</td>\n      <td>0.772665</td>\n      <td>0.414348</td>\n      <td>0.693385</td>\n    </tr>\n    <tr>\n      <td>2048</td>\n      <td>1.855800</td>\n      <td>1.680838</td>\n      <td>0.773619</td>\n      <td>0.416598</td>\n      <td>0.695329</td>\n    </tr>\n    <tr>\n      <td>2560</td>\n      <td>1.842700</td>\n      <td>1.661814</td>\n      <td>0.773028</td>\n      <td>0.413879</td>\n      <td>0.693893</td>\n    </tr>\n    <tr>\n      <td>3072</td>\n      <td>1.827000</td>\n      <td>1.664096</td>\n      <td>0.772125</td>\n      <td>0.411808</td>\n      <td>0.693255</td>\n    </tr>\n    <tr>\n      <td>3584</td>\n      <td>1.828500</td>\n      <td>1.653124</td>\n      <td>0.772310</td>\n      <td>0.414298</td>\n      <td>0.693539</td>\n    </tr>\n    <tr>\n      <td>4096</td>\n      <td>1.819300</td>\n      <td>1.656115</td>\n      <td>0.771975</td>\n      <td>0.413020</td>\n      <td>0.693362</td>\n    </tr>\n    <tr>\n      <td>4608</td>\n      <td>1.805900</td>\n      <td>1.660652</td>\n      <td>0.772301</td>\n      <td>0.412626</td>\n      <td>0.693388</td>\n    </tr>\n    <tr>\n      <td>5120</td>\n      <td>1.778000</td>\n      <td>1.644493</td>\n      <td>0.772808</td>\n      <td>0.413753</td>\n      <td>0.694583</td>\n    </tr>\n    <tr>\n      <td>5632</td>\n      <td>1.770800</td>\n      <td>1.640512</td>\n      <td>0.772375</td>\n      <td>0.412301</td>\n      <td>0.692956</td>\n    </tr>\n    <tr>\n      <td>6144</td>\n      <td>1.767100</td>\n      <td>1.636624</td>\n      <td>0.772884</td>\n      <td>0.414658</td>\n      <td>0.694682</td>\n    </tr>\n    <tr>\n      <td>6656</td>\n      <td>1.772200</td>\n      <td>1.638855</td>\n      <td>0.773756</td>\n      <td>0.414890</td>\n      <td>0.694503</td>\n    </tr>\n    <tr>\n      <td>7168</td>\n      <td>1.766600</td>\n      <td>1.632809</td>\n      <td>0.773255</td>\n      <td>0.414565</td>\n      <td>0.693579</td>\n    </tr>\n    <tr>\n      <td>7680</td>\n      <td>1.765500</td>\n      <td>1.636061</td>\n      <td>0.773124</td>\n      <td>0.414600</td>\n      <td>0.694203</td>\n    </tr>\n    <tr>\n      <td>8192</td>\n      <td>1.770600</td>\n      <td>1.626850</td>\n      <td>0.772846</td>\n      <td>0.413705</td>\n      <td>0.694000</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='9217' max='13458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 9217/13458 13:34:49 < 6:15:00, 0.19 it/s, Epoch 2.05/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>512</td>\n      <td>1.743200</td>\n      <td>1.724787</td>\n      <td>0.771811</td>\n      <td>0.411786</td>\n      <td>0.691962</td>\n    </tr>\n    <tr>\n      <td>1024</td>\n      <td>1.731100</td>\n      <td>1.722753</td>\n      <td>0.772798</td>\n      <td>0.413633</td>\n      <td>0.691759</td>\n    </tr>\n    <tr>\n      <td>1536</td>\n      <td>1.733300</td>\n      <td>1.709278</td>\n      <td>0.772665</td>\n      <td>0.414348</td>\n      <td>0.693385</td>\n    </tr>\n    <tr>\n      <td>2048</td>\n      <td>1.855800</td>\n      <td>1.680838</td>\n      <td>0.773619</td>\n      <td>0.416598</td>\n      <td>0.695329</td>\n    </tr>\n    <tr>\n      <td>2560</td>\n      <td>1.842700</td>\n      <td>1.661814</td>\n      <td>0.773028</td>\n      <td>0.413879</td>\n      <td>0.693893</td>\n    </tr>\n    <tr>\n      <td>3072</td>\n      <td>1.827000</td>\n      <td>1.664096</td>\n      <td>0.772125</td>\n      <td>0.411808</td>\n      <td>0.693255</td>\n    </tr>\n    <tr>\n      <td>3584</td>\n      <td>1.828500</td>\n      <td>1.653124</td>\n      <td>0.772310</td>\n      <td>0.414298</td>\n      <td>0.693539</td>\n    </tr>\n    <tr>\n      <td>4096</td>\n      <td>1.819300</td>\n      <td>1.656115</td>\n      <td>0.771975</td>\n      <td>0.413020</td>\n      <td>0.693362</td>\n    </tr>\n    <tr>\n      <td>4608</td>\n      <td>1.805900</td>\n      <td>1.660652</td>\n      <td>0.772301</td>\n      <td>0.412626</td>\n      <td>0.693388</td>\n    </tr>\n    <tr>\n      <td>5120</td>\n      <td>1.778000</td>\n      <td>1.644493</td>\n      <td>0.772808</td>\n      <td>0.413753</td>\n      <td>0.694583</td>\n    </tr>\n    <tr>\n      <td>5632</td>\n      <td>1.770800</td>\n      <td>1.640512</td>\n      <td>0.772375</td>\n      <td>0.412301</td>\n      <td>0.692956</td>\n    </tr>\n    <tr>\n      <td>6144</td>\n      <td>1.767100</td>\n      <td>1.636624</td>\n      <td>0.772884</td>\n      <td>0.414658</td>\n      <td>0.694682</td>\n    </tr>\n    <tr>\n      <td>6656</td>\n      <td>1.772200</td>\n      <td>1.638855</td>\n      <td>0.773756</td>\n      <td>0.414890</td>\n      <td>0.694503</td>\n    </tr>\n    <tr>\n      <td>7168</td>\n      <td>1.766600</td>\n      <td>1.632809</td>\n      <td>0.773255</td>\n      <td>0.414565</td>\n      <td>0.693579</td>\n    </tr>\n    <tr>\n      <td>7680</td>\n      <td>1.765500</td>\n      <td>1.636061</td>\n      <td>0.773124</td>\n      <td>0.414600</td>\n      <td>0.694203</td>\n    </tr>\n    <tr>\n      <td>8192</td>\n      <td>1.770600</td>\n      <td>1.626850</td>\n      <td>0.772846</td>\n      <td>0.413705</td>\n      <td>0.694000</td>\n    </tr>\n    <tr>\n      <td>8704</td>\n      <td>1.762700</td>\n      <td>1.629631</td>\n      <td>0.773202</td>\n      <td>0.414840</td>\n      <td>0.694156</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='9729' max='13458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 9729/13458 14:21:05 < 5:30:06, 0.19 it/s, Epoch 2.17/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>512</td>\n      <td>1.743200</td>\n      <td>1.724787</td>\n      <td>0.771811</td>\n      <td>0.411786</td>\n      <td>0.691962</td>\n    </tr>\n    <tr>\n      <td>1024</td>\n      <td>1.731100</td>\n      <td>1.722753</td>\n      <td>0.772798</td>\n      <td>0.413633</td>\n      <td>0.691759</td>\n    </tr>\n    <tr>\n      <td>1536</td>\n      <td>1.733300</td>\n      <td>1.709278</td>\n      <td>0.772665</td>\n      <td>0.414348</td>\n      <td>0.693385</td>\n    </tr>\n    <tr>\n      <td>2048</td>\n      <td>1.855800</td>\n      <td>1.680838</td>\n      <td>0.773619</td>\n      <td>0.416598</td>\n      <td>0.695329</td>\n    </tr>\n    <tr>\n      <td>2560</td>\n      <td>1.842700</td>\n      <td>1.661814</td>\n      <td>0.773028</td>\n      <td>0.413879</td>\n      <td>0.693893</td>\n    </tr>\n    <tr>\n      <td>3072</td>\n      <td>1.827000</td>\n      <td>1.664096</td>\n      <td>0.772125</td>\n      <td>0.411808</td>\n      <td>0.693255</td>\n    </tr>\n    <tr>\n      <td>3584</td>\n      <td>1.828500</td>\n      <td>1.653124</td>\n      <td>0.772310</td>\n      <td>0.414298</td>\n      <td>0.693539</td>\n    </tr>\n    <tr>\n      <td>4096</td>\n      <td>1.819300</td>\n      <td>1.656115</td>\n      <td>0.771975</td>\n      <td>0.413020</td>\n      <td>0.693362</td>\n    </tr>\n    <tr>\n      <td>4608</td>\n      <td>1.805900</td>\n      <td>1.660652</td>\n      <td>0.772301</td>\n      <td>0.412626</td>\n      <td>0.693388</td>\n    </tr>\n    <tr>\n      <td>5120</td>\n      <td>1.778000</td>\n      <td>1.644493</td>\n      <td>0.772808</td>\n      <td>0.413753</td>\n      <td>0.694583</td>\n    </tr>\n    <tr>\n      <td>5632</td>\n      <td>1.770800</td>\n      <td>1.640512</td>\n      <td>0.772375</td>\n      <td>0.412301</td>\n      <td>0.692956</td>\n    </tr>\n    <tr>\n      <td>6144</td>\n      <td>1.767100</td>\n      <td>1.636624</td>\n      <td>0.772884</td>\n      <td>0.414658</td>\n      <td>0.694682</td>\n    </tr>\n    <tr>\n      <td>6656</td>\n      <td>1.772200</td>\n      <td>1.638855</td>\n      <td>0.773756</td>\n      <td>0.414890</td>\n      <td>0.694503</td>\n    </tr>\n    <tr>\n      <td>7168</td>\n      <td>1.766600</td>\n      <td>1.632809</td>\n      <td>0.773255</td>\n      <td>0.414565</td>\n      <td>0.693579</td>\n    </tr>\n    <tr>\n      <td>7680</td>\n      <td>1.765500</td>\n      <td>1.636061</td>\n      <td>0.773124</td>\n      <td>0.414600</td>\n      <td>0.694203</td>\n    </tr>\n    <tr>\n      <td>8192</td>\n      <td>1.770600</td>\n      <td>1.626850</td>\n      <td>0.772846</td>\n      <td>0.413705</td>\n      <td>0.694000</td>\n    </tr>\n    <tr>\n      <td>8704</td>\n      <td>1.762700</td>\n      <td>1.629631</td>\n      <td>0.773202</td>\n      <td>0.414840</td>\n      <td>0.694156</td>\n    </tr>\n    <tr>\n      <td>9216</td>\n      <td>1.752800</td>\n      <td>1.626875</td>\n      <td>0.773734</td>\n      <td>0.415179</td>\n      <td>0.695157</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='10241' max='13458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10241/13458 15:07:47 < 4:45:13, 0.19 it/s, Epoch 2.28/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>512</td>\n      <td>1.743200</td>\n      <td>1.724787</td>\n      <td>0.771811</td>\n      <td>0.411786</td>\n      <td>0.691962</td>\n    </tr>\n    <tr>\n      <td>1024</td>\n      <td>1.731100</td>\n      <td>1.722753</td>\n      <td>0.772798</td>\n      <td>0.413633</td>\n      <td>0.691759</td>\n    </tr>\n    <tr>\n      <td>1536</td>\n      <td>1.733300</td>\n      <td>1.709278</td>\n      <td>0.772665</td>\n      <td>0.414348</td>\n      <td>0.693385</td>\n    </tr>\n    <tr>\n      <td>2048</td>\n      <td>1.855800</td>\n      <td>1.680838</td>\n      <td>0.773619</td>\n      <td>0.416598</td>\n      <td>0.695329</td>\n    </tr>\n    <tr>\n      <td>2560</td>\n      <td>1.842700</td>\n      <td>1.661814</td>\n      <td>0.773028</td>\n      <td>0.413879</td>\n      <td>0.693893</td>\n    </tr>\n    <tr>\n      <td>3072</td>\n      <td>1.827000</td>\n      <td>1.664096</td>\n      <td>0.772125</td>\n      <td>0.411808</td>\n      <td>0.693255</td>\n    </tr>\n    <tr>\n      <td>3584</td>\n      <td>1.828500</td>\n      <td>1.653124</td>\n      <td>0.772310</td>\n      <td>0.414298</td>\n      <td>0.693539</td>\n    </tr>\n    <tr>\n      <td>4096</td>\n      <td>1.819300</td>\n      <td>1.656115</td>\n      <td>0.771975</td>\n      <td>0.413020</td>\n      <td>0.693362</td>\n    </tr>\n    <tr>\n      <td>4608</td>\n      <td>1.805900</td>\n      <td>1.660652</td>\n      <td>0.772301</td>\n      <td>0.412626</td>\n      <td>0.693388</td>\n    </tr>\n    <tr>\n      <td>5120</td>\n      <td>1.778000</td>\n      <td>1.644493</td>\n      <td>0.772808</td>\n      <td>0.413753</td>\n      <td>0.694583</td>\n    </tr>\n    <tr>\n      <td>5632</td>\n      <td>1.770800</td>\n      <td>1.640512</td>\n      <td>0.772375</td>\n      <td>0.412301</td>\n      <td>0.692956</td>\n    </tr>\n    <tr>\n      <td>6144</td>\n      <td>1.767100</td>\n      <td>1.636624</td>\n      <td>0.772884</td>\n      <td>0.414658</td>\n      <td>0.694682</td>\n    </tr>\n    <tr>\n      <td>6656</td>\n      <td>1.772200</td>\n      <td>1.638855</td>\n      <td>0.773756</td>\n      <td>0.414890</td>\n      <td>0.694503</td>\n    </tr>\n    <tr>\n      <td>7168</td>\n      <td>1.766600</td>\n      <td>1.632809</td>\n      <td>0.773255</td>\n      <td>0.414565</td>\n      <td>0.693579</td>\n    </tr>\n    <tr>\n      <td>7680</td>\n      <td>1.765500</td>\n      <td>1.636061</td>\n      <td>0.773124</td>\n      <td>0.414600</td>\n      <td>0.694203</td>\n    </tr>\n    <tr>\n      <td>8192</td>\n      <td>1.770600</td>\n      <td>1.626850</td>\n      <td>0.772846</td>\n      <td>0.413705</td>\n      <td>0.694000</td>\n    </tr>\n    <tr>\n      <td>8704</td>\n      <td>1.762700</td>\n      <td>1.629631</td>\n      <td>0.773202</td>\n      <td>0.414840</td>\n      <td>0.694156</td>\n    </tr>\n    <tr>\n      <td>9216</td>\n      <td>1.752800</td>\n      <td>1.626875</td>\n      <td>0.773734</td>\n      <td>0.415179</td>\n      <td>0.695157</td>\n    </tr>\n    <tr>\n      <td>9728</td>\n      <td>1.740500</td>\n      <td>1.627758</td>\n      <td>0.773548</td>\n      <td>0.415436</td>\n      <td>0.694974</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='10753' max='13458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10753/13458 15:55:00 < 4:00:16, 0.19 it/s, Epoch 2.40/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>512</td>\n      <td>1.743200</td>\n      <td>1.724787</td>\n      <td>0.771811</td>\n      <td>0.411786</td>\n      <td>0.691962</td>\n    </tr>\n    <tr>\n      <td>1024</td>\n      <td>1.731100</td>\n      <td>1.722753</td>\n      <td>0.772798</td>\n      <td>0.413633</td>\n      <td>0.691759</td>\n    </tr>\n    <tr>\n      <td>1536</td>\n      <td>1.733300</td>\n      <td>1.709278</td>\n      <td>0.772665</td>\n      <td>0.414348</td>\n      <td>0.693385</td>\n    </tr>\n    <tr>\n      <td>2048</td>\n      <td>1.855800</td>\n      <td>1.680838</td>\n      <td>0.773619</td>\n      <td>0.416598</td>\n      <td>0.695329</td>\n    </tr>\n    <tr>\n      <td>2560</td>\n      <td>1.842700</td>\n      <td>1.661814</td>\n      <td>0.773028</td>\n      <td>0.413879</td>\n      <td>0.693893</td>\n    </tr>\n    <tr>\n      <td>3072</td>\n      <td>1.827000</td>\n      <td>1.664096</td>\n      <td>0.772125</td>\n      <td>0.411808</td>\n      <td>0.693255</td>\n    </tr>\n    <tr>\n      <td>3584</td>\n      <td>1.828500</td>\n      <td>1.653124</td>\n      <td>0.772310</td>\n      <td>0.414298</td>\n      <td>0.693539</td>\n    </tr>\n    <tr>\n      <td>4096</td>\n      <td>1.819300</td>\n      <td>1.656115</td>\n      <td>0.771975</td>\n      <td>0.413020</td>\n      <td>0.693362</td>\n    </tr>\n    <tr>\n      <td>4608</td>\n      <td>1.805900</td>\n      <td>1.660652</td>\n      <td>0.772301</td>\n      <td>0.412626</td>\n      <td>0.693388</td>\n    </tr>\n    <tr>\n      <td>5120</td>\n      <td>1.778000</td>\n      <td>1.644493</td>\n      <td>0.772808</td>\n      <td>0.413753</td>\n      <td>0.694583</td>\n    </tr>\n    <tr>\n      <td>5632</td>\n      <td>1.770800</td>\n      <td>1.640512</td>\n      <td>0.772375</td>\n      <td>0.412301</td>\n      <td>0.692956</td>\n    </tr>\n    <tr>\n      <td>6144</td>\n      <td>1.767100</td>\n      <td>1.636624</td>\n      <td>0.772884</td>\n      <td>0.414658</td>\n      <td>0.694682</td>\n    </tr>\n    <tr>\n      <td>6656</td>\n      <td>1.772200</td>\n      <td>1.638855</td>\n      <td>0.773756</td>\n      <td>0.414890</td>\n      <td>0.694503</td>\n    </tr>\n    <tr>\n      <td>7168</td>\n      <td>1.766600</td>\n      <td>1.632809</td>\n      <td>0.773255</td>\n      <td>0.414565</td>\n      <td>0.693579</td>\n    </tr>\n    <tr>\n      <td>7680</td>\n      <td>1.765500</td>\n      <td>1.636061</td>\n      <td>0.773124</td>\n      <td>0.414600</td>\n      <td>0.694203</td>\n    </tr>\n    <tr>\n      <td>8192</td>\n      <td>1.770600</td>\n      <td>1.626850</td>\n      <td>0.772846</td>\n      <td>0.413705</td>\n      <td>0.694000</td>\n    </tr>\n    <tr>\n      <td>8704</td>\n      <td>1.762700</td>\n      <td>1.629631</td>\n      <td>0.773202</td>\n      <td>0.414840</td>\n      <td>0.694156</td>\n    </tr>\n    <tr>\n      <td>9216</td>\n      <td>1.752800</td>\n      <td>1.626875</td>\n      <td>0.773734</td>\n      <td>0.415179</td>\n      <td>0.695157</td>\n    </tr>\n    <tr>\n      <td>9728</td>\n      <td>1.740500</td>\n      <td>1.627758</td>\n      <td>0.773548</td>\n      <td>0.415436</td>\n      <td>0.694974</td>\n    </tr>\n    <tr>\n      <td>10240</td>\n      <td>1.733600</td>\n      <td>1.624775</td>\n      <td>0.773551</td>\n      <td>0.414502</td>\n      <td>0.694587</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='10756' max='13458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10756/13458 16:30:59 < 4:08:59, 0.18 it/s, Epoch 2.40/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>512</td>\n      <td>1.743200</td>\n      <td>1.724787</td>\n      <td>0.771811</td>\n      <td>0.411786</td>\n      <td>0.691962</td>\n    </tr>\n    <tr>\n      <td>1024</td>\n      <td>1.731100</td>\n      <td>1.722753</td>\n      <td>0.772798</td>\n      <td>0.413633</td>\n      <td>0.691759</td>\n    </tr>\n    <tr>\n      <td>1536</td>\n      <td>1.733300</td>\n      <td>1.709278</td>\n      <td>0.772665</td>\n      <td>0.414348</td>\n      <td>0.693385</td>\n    </tr>\n    <tr>\n      <td>2048</td>\n      <td>1.855800</td>\n      <td>1.680838</td>\n      <td>0.773619</td>\n      <td>0.416598</td>\n      <td>0.695329</td>\n    </tr>\n    <tr>\n      <td>2560</td>\n      <td>1.842700</td>\n      <td>1.661814</td>\n      <td>0.773028</td>\n      <td>0.413879</td>\n      <td>0.693893</td>\n    </tr>\n    <tr>\n      <td>3072</td>\n      <td>1.827000</td>\n      <td>1.664096</td>\n      <td>0.772125</td>\n      <td>0.411808</td>\n      <td>0.693255</td>\n    </tr>\n    <tr>\n      <td>3584</td>\n      <td>1.828500</td>\n      <td>1.653124</td>\n      <td>0.772310</td>\n      <td>0.414298</td>\n      <td>0.693539</td>\n    </tr>\n    <tr>\n      <td>4096</td>\n      <td>1.819300</td>\n      <td>1.656115</td>\n      <td>0.771975</td>\n      <td>0.413020</td>\n      <td>0.693362</td>\n    </tr>\n    <tr>\n      <td>4608</td>\n      <td>1.805900</td>\n      <td>1.660652</td>\n      <td>0.772301</td>\n      <td>0.412626</td>\n      <td>0.693388</td>\n    </tr>\n    <tr>\n      <td>5120</td>\n      <td>1.778000</td>\n      <td>1.644493</td>\n      <td>0.772808</td>\n      <td>0.413753</td>\n      <td>0.694583</td>\n    </tr>\n    <tr>\n      <td>5632</td>\n      <td>1.770800</td>\n      <td>1.640512</td>\n      <td>0.772375</td>\n      <td>0.412301</td>\n      <td>0.692956</td>\n    </tr>\n    <tr>\n      <td>6144</td>\n      <td>1.767100</td>\n      <td>1.636624</td>\n      <td>0.772884</td>\n      <td>0.414658</td>\n      <td>0.694682</td>\n    </tr>\n    <tr>\n      <td>6656</td>\n      <td>1.772200</td>\n      <td>1.638855</td>\n      <td>0.773756</td>\n      <td>0.414890</td>\n      <td>0.694503</td>\n    </tr>\n    <tr>\n      <td>7168</td>\n      <td>1.766600</td>\n      <td>1.632809</td>\n      <td>0.773255</td>\n      <td>0.414565</td>\n      <td>0.693579</td>\n    </tr>\n    <tr>\n      <td>7680</td>\n      <td>1.765500</td>\n      <td>1.636061</td>\n      <td>0.773124</td>\n      <td>0.414600</td>\n      <td>0.694203</td>\n    </tr>\n    <tr>\n      <td>8192</td>\n      <td>1.770600</td>\n      <td>1.626850</td>\n      <td>0.772846</td>\n      <td>0.413705</td>\n      <td>0.694000</td>\n    </tr>\n    <tr>\n      <td>8704</td>\n      <td>1.762700</td>\n      <td>1.629631</td>\n      <td>0.773202</td>\n      <td>0.414840</td>\n      <td>0.694156</td>\n    </tr>\n    <tr>\n      <td>9216</td>\n      <td>1.752800</td>\n      <td>1.626875</td>\n      <td>0.773734</td>\n      <td>0.415179</td>\n      <td>0.695157</td>\n    </tr>\n    <tr>\n      <td>9728</td>\n      <td>1.740500</td>\n      <td>1.627758</td>\n      <td>0.773548</td>\n      <td>0.415436</td>\n      <td>0.694974</td>\n    </tr>\n    <tr>\n      <td>10240</td>\n      <td>1.733600</td>\n      <td>1.624775</td>\n      <td>0.773551</td>\n      <td>0.414502</td>\n      <td>0.694587</td>\n    </tr>\n    <tr>\n      <td>10752</td>\n      <td>1.737800</td>\n      <td>1.626855</td>\n      <td>0.774064</td>\n      <td>0.415522</td>\n      <td>0.694336</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\transformers\\trainer.py:1780\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   1778\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[0;32m   1779\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1780\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1781\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1782\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1783\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1784\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1785\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\transformers\\trainer.py:2118\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   2115\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_step_begin(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[0;32m   2117\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39maccumulate(model):\n\u001B[1;32m-> 2118\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2120\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   2121\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[0;32m   2122\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[0;32m   2123\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[0;32m   2124\u001B[0m ):\n\u001B[0;32m   2125\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[0;32m   2126\u001B[0m     tr_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\transformers\\trainer.py:3045\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[1;34m(self, model, inputs)\u001B[0m\n\u001B[0;32m   3043\u001B[0m         scaled_loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m   3044\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 3045\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maccelerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3047\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\u001B[38;5;241m.\u001B[39mdetach() \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mgradient_accumulation_steps\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\accelerate\\accelerator.py:2013\u001B[0m, in \u001B[0;36mAccelerator.backward\u001B[1;34m(self, loss, **kwargs)\u001B[0m\n\u001B[0;32m   2011\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscaler\u001B[38;5;241m.\u001B[39mscale(loss)\u001B[38;5;241m.\u001B[39mbackward(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   2012\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2013\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\torch\\_tensor.py:522\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    512\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    513\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    514\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    515\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    520\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    521\u001B[0m     )\n\u001B[1;32m--> 522\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    524\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\torch\\autograd\\__init__.py:266\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    261\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    263\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    264\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 266\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    274\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pipe = pipeline('text2text-generation', model=model, tokenizer=tokenizer, device=0)\n",
    "text = ds['validation'][200]['article']\n",
    "target = ds['validation'][200]['highlights']\n",
    "print(target)\n",
    "print(\"----------------------------------\\n\")\n",
    "pip_res = pipe(\"Generate summary:\\n\" + text, max_length = 64)\n",
    "t5_summary = pip_res[0]['generated_text']\n",
    "print(t5_summary)\n",
    "print(\"----------------------------------\\n\")\n",
    "print(\" Rouge-L between label and generate summary with t5 model is \", rouge.get_scores(target, t5_summary)[0]['rouge-l'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T06:54:09.159513300Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step8.5: Retrain model if needed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./summary/last-checkpoint-3072\")\n",
    "print(\"Model weights loaded...\\n\")\n",
    "\n",
    "pipe = pipeline('text2text-generation', model=model, tokenizer=tokenizer, device=0)\n",
    "text = ds['validation'][200]['article']\n",
    "target = ds['validation'][200]['highlights']\n",
    "print(target)\n",
    "print(\"----------------------------------\\n\")\n",
    "pip_res = pipe(\"Generate summary:\\n\" + text, max_length = 64)\n",
    "t5_summary = pip_res[0]['generated_text']\n",
    "print(t5_summary)\n",
    "print(\"----------------------------------\\n\")\n",
    "print(\" Rouge-L between label and generate summary with t5 model is \", rouge.get_scores(target, t5_summary)[0]['rouge-l'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T06:54:09.183512400Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "validations = ds['validation']\n",
    "texts: list[str] = validations['article']\n",
    "labels: list[str] = validations['highlights']\n",
    "t5_summaries : list[str] = [pipe(each, max_length = 64)[0]['generated_text'] for each in texts]\n",
    "rouge.get_scores(labels, t5_summaries, avg=True)['rouge-l']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T06:54:09.201515300Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "text_generator = pipeline(\"text2text-generation\")\n",
    "\n",
    "# List of input prompts\n",
    "input_prompts = [\n",
    "    \"Once upon a time, there was a king who ruled over a prosperous kingdom.\",\n",
    "    \"In a galaxy far, far away, a young Jedi embarked on a journey to defeat the Sith.\",\n",
    "    \"The scientist conducted an experiment that would change the course of human history.\"\n",
    "]\n",
    "\n",
    "# Generate results for each input prompt\n",
    "results = [text_generator(prompt) for prompt in input_prompts]\n",
    "\n",
    "# Print results\n",
    "for input_prompt, result in zip(input_prompts, results):\n",
    "    print(\"Input Prompt:\", input_prompt)\n",
    "    print(\"Generated Text:\", result)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T06:54:09.202514800Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step9: Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "from heapq import nlargest\n",
    "from datasets import load_dataset\n",
    "from rouge import Rouge\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "stopwords = list(STOP_WORDS)\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T06:54:09.240512500Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def select_main_sentence(text, punctuation, nlp):\n",
    "    summary_length = 3\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]\n",
    "    punctuation = punctuation + '\\n'\n",
    "    sentence_tokens = [sent for sent in doc.sents]\n",
    "    \n",
    "    word_frequencies = {}\n",
    "    for word in doc:\n",
    "        if word.text.lower() not in stopwords:\n",
    "            if word.text.lower() not in punctuation:\n",
    "                if word.text not in word_frequencies.keys():\n",
    "                    word_frequencies[word.text] = 1\n",
    "                else:\n",
    "                    word_frequencies[word.text] += 1\n",
    "\n",
    "    sentence_scores = {}\n",
    "    for sent in sentence_tokens:\n",
    "        for word in sent:\n",
    "            if word.text.lower() in word_frequencies.keys():\n",
    "                if sent not in sentence_scores.keys():\n",
    "                    sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
    "                else:\n",
    "                    sentence_scores[sent] += word_frequencies[word.text.lower()]\n",
    "         \n",
    "    summary = nlargest(summary_length, sentence_scores, key = sentence_scores.get)\n",
    "    return summary"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T06:54:09.242513500Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T06:54:09.245513700Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"\\n----------------------------article---------------------------------------\\n\")\n",
    "text = ds['validation'][1400]['article']\n",
    "print(text)\n",
    "print(\"\\n----------------------------label---------------------------------------\\n\")\n",
    "target = ds['validation'][1400]['highlights']\n",
    "print(target)\n",
    "print(\"\\n----------------------------generate summary---------------------------------------\")\n",
    "summary = select_main_sentence(text, punctuation, nlp)\n",
    "generate_summary = \"\"\n",
    "for each in summary:\n",
    "    generate_summary = generate_summary + str(each)\n",
    "print(generate_summary)\n",
    "print(\" Rouge-L: \", rouge.get_scores(target, generate_summary)[0]['rouge-l'])\n",
    "\n",
    "print(\"\\n----------------------------generate summary t5 model---------------------------------------\")\n",
    "pip_res = pipe(\"Generate summary:\\n\" + text, max_length = 64)\n",
    "t5_summary = pip_res[0]['generated_text']\n",
    "print(t5_summary)\n",
    "print(\" Rouge-L between label and generate summary with t5 model is \", rouge.get_scores(target, t5_summary)[0]['rouge-l'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T06:54:09.246514200Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T06:54:09.247512500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T06:54:09.249512600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T06:54:09.250512900Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
