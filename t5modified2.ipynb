{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:55:04.127816300Z",
     "start_time": "2024-04-24T15:54:55.254503900Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments, AutoModelForPreTraining, pipeline\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['article', 'highlights', 'id'],\n        num_rows: 272757\n    })\n    test: Dataset({\n        features: ['article', 'highlights', 'id'],\n        num_rows: 14356\n    })\n})"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"cnn_dailymail\", \"1.0.0\", split='train')\n",
    "ds = ds.train_test_split(test_size=.05, shuffle=True)\n",
    "ds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:55:12.593017100Z",
     "start_time": "2024-04-24T15:55:04.130817800Z"
    }
   },
   "id": "59b5f2d7c0298a13",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:55:12.653019200Z",
     "start_time": "2024-04-24T15:55:12.583019400Z"
    }
   },
   "id": "affc02ff39222672",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded...\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"google-t5/t5-small\", max_seq_len=1024)\n",
    "#model = T5ForConditionalGeneration.from_pretrained(\"google-t5/t5-small\", max_memory = 1024)\n",
    "#model = T5ForConditionalGeneration.from_pretrained(\"./summary/last-checkpoint-10240\", max_memory = 1024)\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google-t5/t5-small\", max_memory = 1024)\n",
    "print(\"Model weights loaded...\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:55:14.138020500Z",
     "start_time": "2024-04-24T15:55:12.648024900Z"
    }
   },
   "id": "2a52ba1dd7db5f70",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def process_func(examples):\n",
    "    contents = ['Generate summary: \\n' + e for e in examples['article']]\n",
    "    inputs = tokenizer(contents, max_length=1024, truncation=True)\n",
    "    labels = tokenizer(text_target=examples['highlights'], max_length=128, truncation=True)\n",
    "    inputs['labels'] = labels['input_ids']\n",
    "    return inputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:55:14.166016900Z",
     "start_time": "2024-04-24T15:55:14.138020500Z"
    }
   },
   "id": "cd769648c2232091",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/272757 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "37aa67f3aeff41e591d1ff8199fe5e3f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m tokenized_ds \u001B[38;5;241m=\u001B[39m \u001B[43mds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\datasets\\dataset_dict.py:868\u001B[0m, in \u001B[0;36mDatasetDict.map\u001B[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001B[0m\n\u001B[0;32m    865\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cache_file_names \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    866\u001B[0m     cache_file_names \u001B[38;5;241m=\u001B[39m {k: \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m}\n\u001B[0;32m    867\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DatasetDict(\n\u001B[1;32m--> 868\u001B[0m     {\n\u001B[0;32m    869\u001B[0m         k: dataset\u001B[38;5;241m.\u001B[39mmap(\n\u001B[0;32m    870\u001B[0m             function\u001B[38;5;241m=\u001B[39mfunction,\n\u001B[0;32m    871\u001B[0m             with_indices\u001B[38;5;241m=\u001B[39mwith_indices,\n\u001B[0;32m    872\u001B[0m             with_rank\u001B[38;5;241m=\u001B[39mwith_rank,\n\u001B[0;32m    873\u001B[0m             input_columns\u001B[38;5;241m=\u001B[39minput_columns,\n\u001B[0;32m    874\u001B[0m             batched\u001B[38;5;241m=\u001B[39mbatched,\n\u001B[0;32m    875\u001B[0m             batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m    876\u001B[0m             drop_last_batch\u001B[38;5;241m=\u001B[39mdrop_last_batch,\n\u001B[0;32m    877\u001B[0m             remove_columns\u001B[38;5;241m=\u001B[39mremove_columns,\n\u001B[0;32m    878\u001B[0m             keep_in_memory\u001B[38;5;241m=\u001B[39mkeep_in_memory,\n\u001B[0;32m    879\u001B[0m             load_from_cache_file\u001B[38;5;241m=\u001B[39mload_from_cache_file,\n\u001B[0;32m    880\u001B[0m             cache_file_name\u001B[38;5;241m=\u001B[39mcache_file_names[k],\n\u001B[0;32m    881\u001B[0m             writer_batch_size\u001B[38;5;241m=\u001B[39mwriter_batch_size,\n\u001B[0;32m    882\u001B[0m             features\u001B[38;5;241m=\u001B[39mfeatures,\n\u001B[0;32m    883\u001B[0m             disable_nullable\u001B[38;5;241m=\u001B[39mdisable_nullable,\n\u001B[0;32m    884\u001B[0m             fn_kwargs\u001B[38;5;241m=\u001B[39mfn_kwargs,\n\u001B[0;32m    885\u001B[0m             num_proc\u001B[38;5;241m=\u001B[39mnum_proc,\n\u001B[0;32m    886\u001B[0m             desc\u001B[38;5;241m=\u001B[39mdesc,\n\u001B[0;32m    887\u001B[0m         )\n\u001B[0;32m    888\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m k, dataset \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems()\n\u001B[0;32m    889\u001B[0m     }\n\u001B[0;32m    890\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\datasets\\dataset_dict.py:869\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    865\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cache_file_names \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    866\u001B[0m     cache_file_names \u001B[38;5;241m=\u001B[39m {k: \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m}\n\u001B[0;32m    867\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DatasetDict(\n\u001B[0;32m    868\u001B[0m     {\n\u001B[1;32m--> 869\u001B[0m         k: \u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    870\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    871\u001B[0m \u001B[43m            \u001B[49m\u001B[43mwith_indices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwith_indices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    872\u001B[0m \u001B[43m            \u001B[49m\u001B[43mwith_rank\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwith_rank\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    873\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_columns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    874\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbatched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatched\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    875\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    876\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdrop_last_batch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdrop_last_batch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[43m            \u001B[49m\u001B[43mremove_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremove_columns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    878\u001B[0m \u001B[43m            \u001B[49m\u001B[43mkeep_in_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_in_memory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    879\u001B[0m \u001B[43m            \u001B[49m\u001B[43mload_from_cache_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mload_from_cache_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    880\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcache_file_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_file_names\u001B[49m\u001B[43m[\u001B[49m\u001B[43mk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    881\u001B[0m \u001B[43m            \u001B[49m\u001B[43mwriter_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwriter_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    882\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    883\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdisable_nullable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisable_nullable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    884\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfn_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfn_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    885\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnum_proc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_proc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    886\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdesc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdesc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    887\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    888\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m k, dataset \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems()\n\u001B[0;32m    889\u001B[0m     }\n\u001B[0;32m    890\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\datasets\\arrow_dataset.py:593\u001B[0m, in \u001B[0;36mtransmit_tasks.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    591\u001B[0m     \u001B[38;5;28mself\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mself\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    592\u001B[0m \u001B[38;5;66;03m# apply actual function\u001B[39;00m\n\u001B[1;32m--> 593\u001B[0m out: Union[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDatasetDict\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    594\u001B[0m datasets: List[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(out\u001B[38;5;241m.\u001B[39mvalues()) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(out, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m [out]\n\u001B[0;32m    595\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m dataset \u001B[38;5;129;01min\u001B[39;00m datasets:\n\u001B[0;32m    596\u001B[0m     \u001B[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\datasets\\arrow_dataset.py:558\u001B[0m, in \u001B[0;36mtransmit_format.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    551\u001B[0m self_format \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    552\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_type,\n\u001B[0;32m    553\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mformat_kwargs\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_kwargs,\n\u001B[0;32m    554\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_columns,\n\u001B[0;32m    555\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_all_columns\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_all_columns,\n\u001B[0;32m    556\u001B[0m }\n\u001B[0;32m    557\u001B[0m \u001B[38;5;66;03m# apply actual function\u001B[39;00m\n\u001B[1;32m--> 558\u001B[0m out: Union[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDatasetDict\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    559\u001B[0m datasets: List[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(out\u001B[38;5;241m.\u001B[39mvalues()) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(out, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m [out]\n\u001B[0;32m    560\u001B[0m \u001B[38;5;66;03m# re-apply format to the output\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\datasets\\arrow_dataset.py:3105\u001B[0m, in \u001B[0;36mDataset.map\u001B[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001B[0m\n\u001B[0;32m   3099\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m transformed_dataset \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   3100\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m hf_tqdm(\n\u001B[0;32m   3101\u001B[0m         unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m examples\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   3102\u001B[0m         total\u001B[38;5;241m=\u001B[39mpbar_total,\n\u001B[0;32m   3103\u001B[0m         desc\u001B[38;5;241m=\u001B[39mdesc \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMap\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   3104\u001B[0m     ) \u001B[38;5;28;01mas\u001B[39;00m pbar:\n\u001B[1;32m-> 3105\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m rank, done, content \u001B[38;5;129;01min\u001B[39;00m Dataset\u001B[38;5;241m.\u001B[39m_map_single(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdataset_kwargs):\n\u001B[0;32m   3106\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m done:\n\u001B[0;32m   3107\u001B[0m                 shards_done \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\datasets\\arrow_dataset.py:3482\u001B[0m, in \u001B[0;36mDataset._map_single\u001B[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001B[0m\n\u001B[0;32m   3478\u001B[0m indices \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\n\u001B[0;32m   3479\u001B[0m     \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m*\u001B[39m(\u001B[38;5;28mslice\u001B[39m(i, i \u001B[38;5;241m+\u001B[39m batch_size)\u001B[38;5;241m.\u001B[39mindices(shard\u001B[38;5;241m.\u001B[39mnum_rows)))\n\u001B[0;32m   3480\u001B[0m )  \u001B[38;5;66;03m# Something simpler?\u001B[39;00m\n\u001B[0;32m   3481\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3482\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[43mapply_function_on_filtered_inputs\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3483\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3484\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3485\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_same_num_examples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mshard\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlist_indexes\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3486\u001B[0m \u001B[43m        \u001B[49m\u001B[43moffset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moffset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3487\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3488\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m NumExamplesMismatchError:\n\u001B[0;32m   3489\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m DatasetTransformationNotAllowedError(\n\u001B[0;32m   3490\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3491\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\datasets\\arrow_dataset.py:3361\u001B[0m, in \u001B[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001B[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001B[0m\n\u001B[0;32m   3359\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m with_rank:\n\u001B[0;32m   3360\u001B[0m     additional_args \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (rank,)\n\u001B[1;32m-> 3361\u001B[0m processed_inputs \u001B[38;5;241m=\u001B[39m function(\u001B[38;5;241m*\u001B[39mfn_args, \u001B[38;5;241m*\u001B[39madditional_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfn_kwargs)\n\u001B[0;32m   3362\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(processed_inputs, LazyDict):\n\u001B[0;32m   3363\u001B[0m     processed_inputs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m   3364\u001B[0m         k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m processed_inputs\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m processed_inputs\u001B[38;5;241m.\u001B[39mkeys_to_format\n\u001B[0;32m   3365\u001B[0m     }\n",
      "Cell \u001B[1;32mIn[6], line 3\u001B[0m, in \u001B[0;36mprocess_func\u001B[1;34m(examples)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprocess_func\u001B[39m(examples):\n\u001B[0;32m      2\u001B[0m     contents \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGenerate summary: \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m e \u001B[38;5;28;01mfor\u001B[39;00m e \u001B[38;5;129;01min\u001B[39;00m examples[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124marticle\u001B[39m\u001B[38;5;124m'\u001B[39m]]\n\u001B[1;32m----> 3\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m \u001B[43mtokenizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcontents\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1024\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtruncation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m     labels \u001B[38;5;241m=\u001B[39m tokenizer(text_target\u001B[38;5;241m=\u001B[39mexamples[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhighlights\u001B[39m\u001B[38;5;124m'\u001B[39m], max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m128\u001B[39m, truncation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      5\u001B[0m     inputs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m labels[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2872\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.__call__\u001B[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[0;32m   2870\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_in_target_context_manager:\n\u001B[0;32m   2871\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_switch_to_input_mode()\n\u001B[1;32m-> 2872\u001B[0m     encodings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_one(text\u001B[38;5;241m=\u001B[39mtext, text_pair\u001B[38;5;241m=\u001B[39mtext_pair, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mall_kwargs)\n\u001B[0;32m   2873\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m text_target \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2874\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_switch_to_target_mode()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2958\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase._call_one\u001B[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[0;32m   2953\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   2954\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch length of `text`: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(text)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not match batch length of `text_pair`:\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2955\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(text_pair)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2956\u001B[0m         )\n\u001B[0;32m   2957\u001B[0m     batch_text_or_text_pairs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(text, text_pair)) \u001B[38;5;28;01mif\u001B[39;00m text_pair \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m text\n\u001B[1;32m-> 2958\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_encode_plus(\n\u001B[0;32m   2959\u001B[0m         batch_text_or_text_pairs\u001B[38;5;241m=\u001B[39mbatch_text_or_text_pairs,\n\u001B[0;32m   2960\u001B[0m         add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[0;32m   2961\u001B[0m         padding\u001B[38;5;241m=\u001B[39mpadding,\n\u001B[0;32m   2962\u001B[0m         truncation\u001B[38;5;241m=\u001B[39mtruncation,\n\u001B[0;32m   2963\u001B[0m         max_length\u001B[38;5;241m=\u001B[39mmax_length,\n\u001B[0;32m   2964\u001B[0m         stride\u001B[38;5;241m=\u001B[39mstride,\n\u001B[0;32m   2965\u001B[0m         is_split_into_words\u001B[38;5;241m=\u001B[39mis_split_into_words,\n\u001B[0;32m   2966\u001B[0m         pad_to_multiple_of\u001B[38;5;241m=\u001B[39mpad_to_multiple_of,\n\u001B[0;32m   2967\u001B[0m         return_tensors\u001B[38;5;241m=\u001B[39mreturn_tensors,\n\u001B[0;32m   2968\u001B[0m         return_token_type_ids\u001B[38;5;241m=\u001B[39mreturn_token_type_ids,\n\u001B[0;32m   2969\u001B[0m         return_attention_mask\u001B[38;5;241m=\u001B[39mreturn_attention_mask,\n\u001B[0;32m   2970\u001B[0m         return_overflowing_tokens\u001B[38;5;241m=\u001B[39mreturn_overflowing_tokens,\n\u001B[0;32m   2971\u001B[0m         return_special_tokens_mask\u001B[38;5;241m=\u001B[39mreturn_special_tokens_mask,\n\u001B[0;32m   2972\u001B[0m         return_offsets_mapping\u001B[38;5;241m=\u001B[39mreturn_offsets_mapping,\n\u001B[0;32m   2973\u001B[0m         return_length\u001B[38;5;241m=\u001B[39mreturn_length,\n\u001B[0;32m   2974\u001B[0m         verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[0;32m   2975\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   2976\u001B[0m     )\n\u001B[0;32m   2977\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2978\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencode_plus(\n\u001B[0;32m   2979\u001B[0m         text\u001B[38;5;241m=\u001B[39mtext,\n\u001B[0;32m   2980\u001B[0m         text_pair\u001B[38;5;241m=\u001B[39mtext_pair,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2996\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   2997\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3149\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001B[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[0;32m   3139\u001B[0m \u001B[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001B[39;00m\n\u001B[0;32m   3140\u001B[0m padding_strategy, truncation_strategy, max_length, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_padding_truncation_strategies(\n\u001B[0;32m   3141\u001B[0m     padding\u001B[38;5;241m=\u001B[39mpadding,\n\u001B[0;32m   3142\u001B[0m     truncation\u001B[38;5;241m=\u001B[39mtruncation,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3146\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   3147\u001B[0m )\n\u001B[1;32m-> 3149\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_encode_plus(\n\u001B[0;32m   3150\u001B[0m     batch_text_or_text_pairs\u001B[38;5;241m=\u001B[39mbatch_text_or_text_pairs,\n\u001B[0;32m   3151\u001B[0m     add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[0;32m   3152\u001B[0m     padding_strategy\u001B[38;5;241m=\u001B[39mpadding_strategy,\n\u001B[0;32m   3153\u001B[0m     truncation_strategy\u001B[38;5;241m=\u001B[39mtruncation_strategy,\n\u001B[0;32m   3154\u001B[0m     max_length\u001B[38;5;241m=\u001B[39mmax_length,\n\u001B[0;32m   3155\u001B[0m     stride\u001B[38;5;241m=\u001B[39mstride,\n\u001B[0;32m   3156\u001B[0m     is_split_into_words\u001B[38;5;241m=\u001B[39mis_split_into_words,\n\u001B[0;32m   3157\u001B[0m     pad_to_multiple_of\u001B[38;5;241m=\u001B[39mpad_to_multiple_of,\n\u001B[0;32m   3158\u001B[0m     return_tensors\u001B[38;5;241m=\u001B[39mreturn_tensors,\n\u001B[0;32m   3159\u001B[0m     return_token_type_ids\u001B[38;5;241m=\u001B[39mreturn_token_type_ids,\n\u001B[0;32m   3160\u001B[0m     return_attention_mask\u001B[38;5;241m=\u001B[39mreturn_attention_mask,\n\u001B[0;32m   3161\u001B[0m     return_overflowing_tokens\u001B[38;5;241m=\u001B[39mreturn_overflowing_tokens,\n\u001B[0;32m   3162\u001B[0m     return_special_tokens_mask\u001B[38;5;241m=\u001B[39mreturn_special_tokens_mask,\n\u001B[0;32m   3163\u001B[0m     return_offsets_mapping\u001B[38;5;241m=\u001B[39mreturn_offsets_mapping,\n\u001B[0;32m   3164\u001B[0m     return_length\u001B[38;5;241m=\u001B[39mreturn_length,\n\u001B[0;32m   3165\u001B[0m     verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[0;32m   3166\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   3167\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\transformers\\tokenization_utils.py:803\u001B[0m, in \u001B[0;36mPreTrainedTokenizer._batch_encode_plus\u001B[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[0;32m    800\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    801\u001B[0m     ids, pair_ids \u001B[38;5;241m=\u001B[39m ids_or_pair_ids\n\u001B[1;32m--> 803\u001B[0m first_ids \u001B[38;5;241m=\u001B[39m \u001B[43mget_input_ids\u001B[49m\u001B[43m(\u001B[49m\u001B[43mids\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    804\u001B[0m second_ids \u001B[38;5;241m=\u001B[39m get_input_ids(pair_ids) \u001B[38;5;28;01mif\u001B[39;00m pair_ids \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    805\u001B[0m input_ids\u001B[38;5;241m.\u001B[39mappend((first_ids, second_ids))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\transformers\\tokenization_utils.py:770\u001B[0m, in \u001B[0;36mPreTrainedTokenizer._batch_encode_plus.<locals>.get_input_ids\u001B[1;34m(text)\u001B[0m\n\u001B[0;32m    768\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_input_ids\u001B[39m(text):\n\u001B[0;32m    769\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(text, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m--> 770\u001B[0m         tokens \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenize(text, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    771\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconvert_tokens_to_ids(tokens)\n\u001B[0;32m    772\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(text, (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(text) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(text[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mstr\u001B[39m):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:386\u001B[0m, in \u001B[0;36mT5Tokenizer.tokenize\u001B[1;34m(self, text, **kwargs)\u001B[0m\n\u001B[0;32m    381\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    382\u001B[0m \u001B[38;5;124;03mConverts a string to a list of tokens. If `self.legacy` is set to `False`, a prefix token is added unless the\u001B[39;00m\n\u001B[0;32m    383\u001B[0m \u001B[38;5;124;03mfirst token is special.\u001B[39;00m\n\u001B[0;32m    384\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    385\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlegacy \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(text) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 386\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mtokenize(text, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    388\u001B[0m text \u001B[38;5;241m=\u001B[39m text\u001B[38;5;241m.\u001B[39mreplace(SPIECE_UNDERLINE, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    389\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_prefix_space:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\transformers\\tokenization_utils.py:617\u001B[0m, in \u001B[0;36mPreTrainedTokenizer.tokenize\u001B[1;34m(self, text, **kwargs)\u001B[0m\n\u001B[0;32m    615\u001B[0m         tokenized_text\u001B[38;5;241m.\u001B[39mappend(token)\n\u001B[0;32m    616\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 617\u001B[0m         tokenized_text\u001B[38;5;241m.\u001B[39mextend(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tokenize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    618\u001B[0m \u001B[38;5;66;03m# [\"This\", \" is\", \" something\", \"<special_token_1>\", \"else\"]\u001B[39;00m\n\u001B[0;32m    619\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m tokenized_text\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:412\u001B[0m, in \u001B[0;36mT5Tokenizer._tokenize\u001B[1;34m(self, text, **kwargs)\u001B[0m\n\u001B[0;32m    402\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_tokenize\u001B[39m(\u001B[38;5;28mself\u001B[39m, text, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    403\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    404\u001B[0m \u001B[38;5;124;03m    Returns a tokenized string.\u001B[39;00m\n\u001B[0;32m    405\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    410\u001B[0m \u001B[38;5;124;03m    `self.tokenizer.sp_model.encode(\"<unk> Hey\", out_type = str)[4:]`.\u001B[39;00m\n\u001B[0;32m    411\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 412\u001B[0m     tokens \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msp_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    413\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlegacy \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m text\u001B[38;5;241m.\u001B[39mstartswith((SPIECE_UNDERLINE, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m)):\n\u001B[0;32m    414\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m tokens\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\sentencepiece\\__init__.py:552\u001B[0m, in \u001B[0;36mSentencePieceProcessor.Encode\u001B[1;34m(self, input, out_type, add_bos, add_eos, reverse, emit_unk_piece, enable_sampling, nbest_size, alpha, num_threads)\u001B[0m\n\u001B[0;32m    549\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_EncodeAsIds(\u001B[38;5;28minput\u001B[39m, enable_sampling, nbest_size,\n\u001B[0;32m    550\u001B[0m                            alpha, add_bos, add_eos, reverse, emit_unk_piece)\n\u001B[0;32m    551\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m out_type \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28mstr\u001B[39m:\n\u001B[1;32m--> 552\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_EncodeAsPieces\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menable_sampling\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnbest_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    553\u001B[0m \u001B[43m                              \u001B[49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madd_bos\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madd_eos\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreverse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43memit_unk_piece\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    554\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m out_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mserialized_proto\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m out_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mproto\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    555\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_EncodeAsSerializedProto(\u001B[38;5;28minput\u001B[39m, enable_sampling, nbest_size,\n\u001B[0;32m    556\u001B[0m                                        alpha, add_bos, add_eos, reverse, emit_unk_piece)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "tokenized_ds = ds.map(process_func, batched=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:55:26.923018Z",
     "start_time": "2024-04-24T15:55:14.152018300Z"
    }
   },
   "id": "3c10c744bf9ce317",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer.decode(tokenized_ds['train'][0]['input_ids'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T15:55:26.924017800Z"
    }
   },
   "id": "a556b2bb129058cb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer.decode(tokenized_ds['train'][0]['labels'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:55:26.926018400Z",
     "start_time": "2024-04-24T15:55:26.925019900Z"
    }
   },
   "id": "c9306df58018a0ee",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ds['train'][0]['highlights']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T15:55:26.927018Z"
    }
   },
   "id": "735659d716b19a0c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rouge import Rouge\n",
    "\n",
    "rouge = Rouge()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T15:55:26.929017700Z"
    }
   },
   "id": "fadc5981a1c5bc51",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def compute_metric(evalPred):\n",
    "    preds, labels = evalPred\n",
    "    decode_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decode_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    decode_preds = [\" \".join(p) for p in decode_preds]\n",
    "    decode_labels = [\" \".join(p) for p in decode_labels]\n",
    "    scores = rouge.get_scores(decode_preds, decode_labels, avg=True)\n",
    "    return {\n",
    "        \"rouge-1\": scores['rouge-1']['f'],\n",
    "        \"rouge-2\": scores['rouge-2']['f'],\n",
    "        \"rouge-l\": scores['rouge-l']['f']\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T15:55:26.930017400Z"
    }
   },
   "id": "d1d1c70438156eb4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./summary\",\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=8,\n",
    "    warmup_steps=128,\n",
    "    logging_steps=512,\n",
    "    logging_dir=\"./logging\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=512,\n",
    "    save_total_limit=5,     # save the last 5 model\n",
    "    metric_for_best_model=\"rouge-l\",\n",
    "    predict_with_generate=True,  # must set True\n",
    "    #load_best_model_at_end=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:55:26.939018100Z",
     "start_time": "2024-04-24T15:55:26.931018800Z"
    }
   },
   "id": "629dcdc4e90a5e8c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'max_seq_length'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[95], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m trainer \u001B[38;5;241m=\u001B[39m \u001B[43mSeq2SeqTrainer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenized_ds\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenized_ds\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtest\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompute_metrics\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompute_metric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_collator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDataCollatorForSeq2Seq\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_seq_length\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1024\u001B[39;49m\n\u001B[0;32m     10\u001B[0m \u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: __init__() got an unexpected keyword argument 'max_seq_length'"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    args=args,\n",
    "    model=model,\n",
    "    train_dataset=tokenized_ds['train'],\n",
    "    eval_dataset=tokenized_ds['test'],\n",
    "    compute_metrics=compute_metric,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer),\n",
    "    max_seq_length = 1024\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:45:48.121857300Z",
     "start_time": "2024-04-24T15:45:48.090856100Z"
    }
   },
   "id": "74cd6e2cc9f4f5c5",
   "execution_count": 95
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='513' max='4261' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 513/4261 32:11 < 3:56:09, 0.26 it/s, Epoch 0.12/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1025' max='4261' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1025/4261 1:26:06 < 4:32:23, 0.20 it/s, Epoch 0.24/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>512</td>\n      <td>1.964100</td>\n      <td>1.699828</td>\n      <td>0.753090</td>\n      <td>0.383804</td>\n      <td>0.674303</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1537' max='4261' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1537/4261 2:18:44 < 4:06:12, 0.18 it/s, Epoch 0.36/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>512</td>\n      <td>1.964100</td>\n      <td>1.699828</td>\n      <td>0.753090</td>\n      <td>0.383804</td>\n      <td>0.674303</td>\n    </tr>\n    <tr>\n      <td>1024</td>\n      <td>1.880000</td>\n      <td>1.688986</td>\n      <td>0.752873</td>\n      <td>0.382462</td>\n      <td>0.673876</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2049' max='4261' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2049/4261 3:10:30 < 3:25:52, 0.18 it/s, Epoch 0.48/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>512</td>\n      <td>1.964100</td>\n      <td>1.699828</td>\n      <td>0.753090</td>\n      <td>0.383804</td>\n      <td>0.674303</td>\n    </tr>\n    <tr>\n      <td>1024</td>\n      <td>1.880000</td>\n      <td>1.688986</td>\n      <td>0.752873</td>\n      <td>0.382462</td>\n      <td>0.673876</td>\n    </tr>\n    <tr>\n      <td>1536</td>\n      <td>1.864000</td>\n      <td>1.678948</td>\n      <td>0.752369</td>\n      <td>0.381655</td>\n      <td>0.673445</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2561' max='4261' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2561/4261 4:03:27 < 2:41:44, 0.18 it/s, Epoch 0.60/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>512</td>\n      <td>1.964100</td>\n      <td>1.699828</td>\n      <td>0.753090</td>\n      <td>0.383804</td>\n      <td>0.674303</td>\n    </tr>\n    <tr>\n      <td>1024</td>\n      <td>1.880000</td>\n      <td>1.688986</td>\n      <td>0.752873</td>\n      <td>0.382462</td>\n      <td>0.673876</td>\n    </tr>\n    <tr>\n      <td>1536</td>\n      <td>1.864000</td>\n      <td>1.678948</td>\n      <td>0.752369</td>\n      <td>0.381655</td>\n      <td>0.673445</td>\n    </tr>\n    <tr>\n      <td>2048</td>\n      <td>1.857000</td>\n      <td>1.678480</td>\n      <td>0.753513</td>\n      <td>0.382921</td>\n      <td>0.674309</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2565' max='4261' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2565/4261 4:22:19 < 2:53:35, 0.16 it/s, Epoch 0.60/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>512</td>\n      <td>1.964100</td>\n      <td>1.699828</td>\n      <td>0.753090</td>\n      <td>0.383804</td>\n      <td>0.674303</td>\n    </tr>\n    <tr>\n      <td>1024</td>\n      <td>1.880000</td>\n      <td>1.688986</td>\n      <td>0.752873</td>\n      <td>0.382462</td>\n      <td>0.673876</td>\n    </tr>\n    <tr>\n      <td>1536</td>\n      <td>1.864000</td>\n      <td>1.678948</td>\n      <td>0.752369</td>\n      <td>0.381655</td>\n      <td>0.673445</td>\n    </tr>\n    <tr>\n      <td>2048</td>\n      <td>1.857000</td>\n      <td>1.678480</td>\n      <td>0.753513</td>\n      <td>0.382921</td>\n      <td>0.674309</td>\n    </tr>\n    <tr>\n      <td>2560</td>\n      <td>1.854500</td>\n      <td>1.675138</td>\n      <td>0.753197</td>\n      <td>0.383015</td>\n      <td>0.674771</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\transformers\\trainer.py:1780\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   1778\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[0;32m   1779\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1780\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1781\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1782\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1783\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1784\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1785\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\transformers\\trainer.py:2118\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   2115\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_step_begin(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[0;32m   2117\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39maccumulate(model):\n\u001B[1;32m-> 2118\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2120\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   2121\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[0;32m   2122\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[0;32m   2123\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[0;32m   2124\u001B[0m ):\n\u001B[0;32m   2125\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[0;32m   2126\u001B[0m     tr_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\transformers\\trainer.py:3045\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[1;34m(self, model, inputs)\u001B[0m\n\u001B[0;32m   3043\u001B[0m         scaled_loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m   3044\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 3045\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maccelerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3047\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\u001B[38;5;241m.\u001B[39mdetach() \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mgradient_accumulation_steps\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\accelerate\\accelerator.py:2013\u001B[0m, in \u001B[0;36mAccelerator.backward\u001B[1;34m(self, loss, **kwargs)\u001B[0m\n\u001B[0;32m   2011\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscaler\u001B[38;5;241m.\u001B[39mscale(loss)\u001B[38;5;241m.\u001B[39mbackward(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   2012\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2013\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\torch\\_tensor.py:522\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    512\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    513\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    514\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    515\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    520\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    521\u001B[0m     )\n\u001B[1;32m--> 522\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    524\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\torch\\autograd\\__init__.py:266\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    261\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    263\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    264\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 266\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    274\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T14:55:28.997785200Z",
     "start_time": "2024-04-24T10:33:02.508082100Z"
    }
   },
   "id": "62b06af02655c79",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "original_model = T5ForConditionalGeneration.from_pretrained(\"google-t5/t5-small\", max_memory =1024)\n",
    "trained_model = T5ForConditionalGeneration.from_pretrained(\"./summary/checkpoint-2560\", max_memory = 1024)\n",
    "trained_model2 = T5ForConditionalGeneration.from_pretrained(\"./summary/last-checkpoint-10240\", max_memory = 1024)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:21:27.386595500Z",
     "start_time": "2024-04-24T15:21:19.203592Z"
    }
   },
   "id": "d67b2300846bfd0f",
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def comparison(model1, model2, tokenizer, num):\n",
    "    text = ds['test'][num]['article']\n",
    "    target = ds['test'][num]['highlights']\n",
    "    pipe1 = pipeline('text2text-generation', model=model1, tokenizer=tokenizer, device=0)\n",
    "    pipe2 = pipeline('text2text-generation', model=model2, tokenizer=tokenizer, device=0)\n",
    "    print(text)\n",
    "    print(f\"-\"*50)\n",
    "    print(target)\n",
    "    print(f\"-\"*50)\n",
    "    pip_res1 = pipe1(\"Generate summary:\\n\" + text, max_length = 128)\n",
    "    t5_summary1 = pip_res1[0]['generated_text']\n",
    "    print(t5_summary1)\n",
    "    print(f\"-\"*50)\n",
    "    print(\"Rouge-L between label and generate summary with original model is \", rouge.get_scores(target, t5_summary1)[0]['rouge-l'])\n",
    "    print(f\"-\"*50)\n",
    "    \n",
    "    pip_res2 = pipe2(\"Generate summary:\\n\" + text, max_length = 128)\n",
    "    t5_summary2 = pip_res2[0]['generated_text']\n",
    "    print(t5_summary2)\n",
    "    print(f\"-\"*50)\n",
    "    print(\"Rouge-L between label and generate summary with trained model is \", rouge.get_scores(target, t5_summary2)[0]['rouge-l'])\n",
    "    print(f\"-\"*50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:19:58.684261200Z",
     "start_time": "2024-04-24T15:19:58.618183500Z"
    }
   },
   "id": "8983520437da347f",
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CNN) -- Alfred Hitchcock, one of the most famous film directors in the world, has re-emerged into the zeitgeist this year. In August, Hitchcock's \"Vertigo\" displaced \"Citizen Kane\" from its perch at the top of the prestigious Sight & Sound list of the greatest films ever made. There also had been renewed interest in \"Psycho\" on its 50th anniversary two years ago as well as the release of shiny new Blu-ray packages of his films. But not all the attention has been flattering. In September, HBO's film \"The Girl\" dramatized Tippi Hedren's behind-the-scenes horror stories from the making of \"The Birds\" (1963). According to the movie, Hitchcock was obsessed with his protege and sexually abusive. And now comes \"Hitchcock,\" an Oscar wannabe scripted by John J. McLauglin (\"Black Swan\") and directed by Sacha Gervasi (\"Anvil\"), with Anthony Hopkins as the portly English master of suspense and Scarlett Johansson (very good) as \"Psycho\" star Janet Leigh. (By the way, Hitch never won an Academy Award -- until the academy sheepishly coughed up a lifetime achievement consolation prize.) The movie begins, not unpromisingly, with Ed Gein murdering his older brother and Hitchcock stepping in to the frame to deliver one of his mordantly witty teasers. It's a cute joke, but it soon turns sour in facile scenes featuring the tormented and delusional Hitch confiding to an imaginary Gein, presented here as a soul mate, confessor and psychiatrist all rolled into one. It's a terrible idea, and all the more insidious because of the casting: Hopkins' most famous role remains Hannibal Lecter, and \"The Silence of the Lambs\" was influenced by Gein's macabre penchant for taxidermy. Certainly, one of the things that makes \"Psycho\" such a great film is that it takes this monstrous, deviant figure, Norman Bates, and forges a human connection, a slender cord of attraction and empathy between him and Leigh's character, Marion Crane. For all his eccentricity, Anthony Perkins plays Norman as a sensitive, vulnerable, even kindly soul, at the mercy of compulsions he does not comprehend or control. Hitchcock, through his art, humanized a monster. \"Hitchcock,\" on the other hand, chooses to demonize the artist, finding something suspect and distasteful in his pursuit of the Gein story -- itself turned into a kind of obsession -- even as it plays the studio head's dismay for self-congratulatory laughs and cannibalizes Hollywood history. In the most ludicrous scene, the director loses all self-control while wielding a prop knife in the vicinity of a naked Leigh (no matter that the famous shower scene employed a body double). While Hopkins' fearful, arrogant, rather pathetic Hitchcock seizes on \"Psycho\" to persuade himself he's not over the hill (after all, in the previous five years he only had \"Rear Window,\" \"Vertigo,\" \"North by Northwest\" and \"The Wrong Man\" and a couple more masterpieces to his name), his long-suffering wife, Alma Reville (Helen Mirren), watches from the sidelines as he mortgages their home, flirts with Leigh -- his latest blonde -- and pushes back the standards of taste and decency in American cultural life. Alma is indulgent, but only up to a point. She permits herself to embark on a collaboration with a gallant writer friend (Danny Huston), a gesture of artistic independence that Hitch perceives as infidelity, tantamount to adultery. Mirren's pursed, patient, discreet Alma is the real hero of this story. She is not just her husband's sounding board but also his best (uncredited) co-writer, his (uncredited) editor and even his (uncredited) co-director. There is probably some sliver of truth to this, but \"Hitchcock\" plays so fast and loose with the facts it's highly unreliable. And in championing the overlooked Alma, it not only denigrates Hitchcock's reputation but it also slights his many other collaborators, too, including the work of author Robert Bloch, editor George Tomasini and composer Bernard Herrmann. What's worse, this mild, mediocre act of feminist revisionism seems oblivious to the very real, enduring and profound power of \"Psycho,\" which is so much more than just an effective scare machine. If you really want to see an honest movie about Hitchcock's troubled, fetishistic, conflicted, love-hate relationship with women, see \"Psycho,\" \"Vertigo,\" \"Marnie\" or \"Notorious\" -- it's a film he made over and over again his whole life, and better than anyone else ever will.\n",
      "--------------------------------------------------\n",
      "Anthony Hopkins stars as the famous director Alfred Hitchcock . Helen Mirren plays Hitchcock's long-suffering wife, Alma Reville . Alma is the true hero of the story, according to the critic . \"Hitchcock\" chooses to demonize the artist, he says .\n",
      "--------------------------------------------------\n",
      ",,,,,, and a kind of obsession. It's a terrible idea, but it's a terrible idea, and more than anyone else ever will. \"Psycho\" is a film he made over and over again his whole life, and better than anyone else ever will.\n",
      "--------------------------------------------------\n",
      "Rouge-L between label and generate summary with original model is  {'r': 0.10714285714285714, 'p': 0.0967741935483871, 'f': 0.10169491026716485}\n",
      "--------------------------------------------------\n",
      "Alfred Hitchcock has re-emerged into the zeitgeist this year . The film is a great film, but it's a terrible idea . It takes this monstrous, deviant figure, Norman Bates, and forges a human connection .\n",
      "--------------------------------------------------\n",
      "Rouge-L between label and generate summary with trained model is  {'r': 0.13333333333333333, 'p': 0.12903225806451613, 'f': 0.1311475359849505}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "num = 2000\n",
    "comparison(original_model, trained_model, tokenizer, num)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:22:52.637781100Z",
     "start_time": "2024-04-24T15:22:51.051781200Z"
    }
   },
   "id": "d5eba87adc189521",
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CNN) -- Alfred Hitchcock, one of the most famous film directors in the world, has re-emerged into the zeitgeist this year. In August, Hitchcock's \"Vertigo\" displaced \"Citizen Kane\" from its perch at the top of the prestigious Sight & Sound list of the greatest films ever made. There also had been renewed interest in \"Psycho\" on its 50th anniversary two years ago as well as the release of shiny new Blu-ray packages of his films. But not all the attention has been flattering. In September, HBO's film \"The Girl\" dramatized Tippi Hedren's behind-the-scenes horror stories from the making of \"The Birds\" (1963). According to the movie, Hitchcock was obsessed with his protege and sexually abusive. And now comes \"Hitchcock,\" an Oscar wannabe scripted by John J. McLauglin (\"Black Swan\") and directed by Sacha Gervasi (\"Anvil\"), with Anthony Hopkins as the portly English master of suspense and Scarlett Johansson (very good) as \"Psycho\" star Janet Leigh. (By the way, Hitch never won an Academy Award -- until the academy sheepishly coughed up a lifetime achievement consolation prize.) The movie begins, not unpromisingly, with Ed Gein murdering his older brother and Hitchcock stepping in to the frame to deliver one of his mordantly witty teasers. It's a cute joke, but it soon turns sour in facile scenes featuring the tormented and delusional Hitch confiding to an imaginary Gein, presented here as a soul mate, confessor and psychiatrist all rolled into one. It's a terrible idea, and all the more insidious because of the casting: Hopkins' most famous role remains Hannibal Lecter, and \"The Silence of the Lambs\" was influenced by Gein's macabre penchant for taxidermy. Certainly, one of the things that makes \"Psycho\" such a great film is that it takes this monstrous, deviant figure, Norman Bates, and forges a human connection, a slender cord of attraction and empathy between him and Leigh's character, Marion Crane. For all his eccentricity, Anthony Perkins plays Norman as a sensitive, vulnerable, even kindly soul, at the mercy of compulsions he does not comprehend or control. Hitchcock, through his art, humanized a monster. \"Hitchcock,\" on the other hand, chooses to demonize the artist, finding something suspect and distasteful in his pursuit of the Gein story -- itself turned into a kind of obsession -- even as it plays the studio head's dismay for self-congratulatory laughs and cannibalizes Hollywood history. In the most ludicrous scene, the director loses all self-control while wielding a prop knife in the vicinity of a naked Leigh (no matter that the famous shower scene employed a body double). While Hopkins' fearful, arrogant, rather pathetic Hitchcock seizes on \"Psycho\" to persuade himself he's not over the hill (after all, in the previous five years he only had \"Rear Window,\" \"Vertigo,\" \"North by Northwest\" and \"The Wrong Man\" and a couple more masterpieces to his name), his long-suffering wife, Alma Reville (Helen Mirren), watches from the sidelines as he mortgages their home, flirts with Leigh -- his latest blonde -- and pushes back the standards of taste and decency in American cultural life. Alma is indulgent, but only up to a point. She permits herself to embark on a collaboration with a gallant writer friend (Danny Huston), a gesture of artistic independence that Hitch perceives as infidelity, tantamount to adultery. Mirren's pursed, patient, discreet Alma is the real hero of this story. She is not just her husband's sounding board but also his best (uncredited) co-writer, his (uncredited) editor and even his (uncredited) co-director. There is probably some sliver of truth to this, but \"Hitchcock\" plays so fast and loose with the facts it's highly unreliable. And in championing the overlooked Alma, it not only denigrates Hitchcock's reputation but it also slights his many other collaborators, too, including the work of author Robert Bloch, editor George Tomasini and composer Bernard Herrmann. What's worse, this mild, mediocre act of feminist revisionism seems oblivious to the very real, enduring and profound power of \"Psycho,\" which is so much more than just an effective scare machine. If you really want to see an honest movie about Hitchcock's troubled, fetishistic, conflicted, love-hate relationship with women, see \"Psycho,\" \"Vertigo,\" \"Marnie\" or \"Notorious\" -- it's a film he made over and over again his whole life, and better than anyone else ever will.\n",
      "--------------------------------------------------\n",
      "Anthony Hopkins stars as the famous director Alfred Hitchcock . Helen Mirren plays Hitchcock's long-suffering wife, Alma Reville . Alma is the true hero of the story, according to the critic . \"Hitchcock\" chooses to demonize the artist, he says .\n",
      "--------------------------------------------------\n",
      ",,,,,, and a kind of obsession. It's a terrible idea, but it's a terrible idea, and more than anyone else ever will. \"Psycho\" is a film he made over and over again his whole life, and better than anyone else ever will.\n",
      "--------------------------------------------------\n",
      "Rouge-L between label and generate summary with original model is  {'r': 0.10714285714285714, 'p': 0.0967741935483871, 'f': 0.10169491026716485}\n",
      "--------------------------------------------------\n",
      "Alfred Hitchcock has re-emerged into the zeitgeist this year . The film is one of the greatest ever made . It's a terrible idea, and all the more insidious because of the casting .\n",
      "--------------------------------------------------\n",
      "Rouge-L between label and generate summary with trained model is  {'r': 0.18518518518518517, 'p': 0.16129032258064516, 'f': 0.1724137881272296}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "comparison(original_model, trained_model2, tokenizer, num)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:22:53.716783Z",
     "start_time": "2024-04-24T15:22:52.640782200Z"
    }
   },
   "id": "26bfe3ea29184cb0",
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenized_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtokenized_ds\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m2000\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'tokenized_ds' is not defined"
     ]
    }
   ],
   "source": [
    "tokenized_ds['train'][2000]['input_ids']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:54:49.111540300Z",
     "start_time": "2024-04-24T15:54:48.461494Z"
    }
   },
   "id": "d3aaba2af9351ff0",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[96], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrained_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mds\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtest\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43mnum\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43marticle\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\transformers\\generation\\utils.py:1356\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[0m\n\u001B[0;32m   1348\u001B[0m \u001B[38;5;66;03m# 3. Define model inputs\u001B[39;00m\n\u001B[0;32m   1349\u001B[0m \u001B[38;5;66;03m# inputs_tensor has to be defined\u001B[39;00m\n\u001B[0;32m   1350\u001B[0m \u001B[38;5;66;03m# model_input_name is defined if model-specific keyword input is passed\u001B[39;00m\n\u001B[0;32m   1351\u001B[0m \u001B[38;5;66;03m# otherwise model_input_name is None\u001B[39;00m\n\u001B[0;32m   1352\u001B[0m \u001B[38;5;66;03m# all model-specific keyword inputs are removed from `model_kwargs`\u001B[39;00m\n\u001B[0;32m   1353\u001B[0m inputs_tensor, model_input_name, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_model_inputs(\n\u001B[0;32m   1354\u001B[0m     inputs, generation_config\u001B[38;5;241m.\u001B[39mbos_token_id, model_kwargs\n\u001B[0;32m   1355\u001B[0m )\n\u001B[1;32m-> 1356\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[43minputs_tensor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1358\u001B[0m \u001B[38;5;66;03m# 4. Define other model kwargs\u001B[39;00m\n\u001B[0;32m   1359\u001B[0m model_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_attentions\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m generation_config\u001B[38;5;241m.\u001B[39moutput_attentions\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'str' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "trained_model.generate(ds['test'][num]['article'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:52:00.666082700Z",
     "start_time": "2024-04-24T15:51:59.699864100Z"
    }
   },
   "id": "d0f1cf28dc6b8cc7",
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "T5ForConditionalGeneration(\n  (shared): Embedding(32128, 512)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n)"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_model.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:34:29.550527500Z",
     "start_time": "2024-04-24T15:34:29.528528100Z"
    }
   },
   "id": "52d352cc25961580",
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "556aeebec84f0b51"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
