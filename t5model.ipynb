{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1: Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:14:53.359487300Z",
     "start_time": "2024-04-22T02:14:48.512591500Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments, AutoModelForPreTraining, pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2: Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:15:01.524934800Z",
     "start_time": "2024-04-22T02:14:53.361490500Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = load_dataset(\"cnn_dailymail\", \"1.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:15:01.540934400Z",
     "start_time": "2024-04-22T02:15:01.525939200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['article', 'highlights', 'id'],\n        num_rows: 287113\n    })\n    validation: Dataset({\n        features: ['article', 'highlights', 'id'],\n        num_rows: 13368\n    })\n    test: Dataset({\n        features: ['article', 'highlights', 'id'],\n        num_rows: 11490\n    })\n})"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:15:01.589934300Z",
     "start_time": "2024-04-22T02:15:01.541934100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'article': '(CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisdiction over alleged crimes in Palestinian territories. The formal accession was marked with a ceremony at The Hague, in the Netherlands, where the court is based. The Palestinians signed the ICC\\'s founding Rome Statute in January, when they also accepted its jurisdiction over alleged crimes committed \"in the occupied Palestinian territory, including East Jerusalem, since June 13, 2014.\" Later that month, the ICC opened a preliminary examination into the situation in Palestinian territories, paving the way for possible war crimes investigations against Israelis. As members of the court, Palestinians may be subject to counter-charges as well. Israel and the United States, neither of which is an ICC member, opposed the Palestinians\\' efforts to join the body. But Palestinian Foreign Minister Riad al-Malki, speaking at Wednesday\\'s ceremony, said it was a move toward greater justice. \"As Palestine formally becomes a State Party to the Rome Statute today, the world is also a step closer to ending a long era of impunity and injustice,\" he said, according to an ICC news release. \"Indeed, today brings us closer to our shared goals of justice and peace.\" Judge Kuniko Ozaki, a vice president of the ICC, said acceding to the treaty was just the first step for the Palestinians. \"As the Rome Statute today enters into force for the State of Palestine, Palestine acquires all the rights as well as responsibilities that come with being a State Party to the Statute. These are substantive commitments, which cannot be taken lightly,\" she said. Rights group Human Rights Watch welcomed the development. \"Governments seeking to penalize Palestine for joining the ICC should immediately end their pressure, and countries that support universal acceptance of the court\\'s treaty should speak out to welcome its membership,\" said Balkees Jarrah, international justice counsel for the group. \"What\\'s objectionable is the attempts to undermine international justice, not Palestine\\'s decision to join a treaty to which over 100 countries around the world are members.\" In January, when the preliminary ICC examination was opened, Israeli Prime Minister Benjamin Netanyahu described it as an outrage, saying the court was overstepping its boundaries. The United States also said it \"strongly\" disagreed with the court\\'s decision. \"As we have said repeatedly, we do not believe that Palestine is a state and therefore we do not believe that it is eligible to join the ICC,\" the State Department said in a statement. It urged the warring sides to resolve their differences through direct negotiations. \"We will continue to oppose actions against Israel at the ICC as counterproductive to the cause of peace,\" it said. But the ICC begs to differ with the definition of a state for its purposes and refers to the territories as \"Palestine.\" While a preliminary examination is not a formal investigation, it allows the court to review evidence and determine whether to investigate suspects on both sides. Prosecutor Fatou Bensouda said her office would \"conduct its analysis in full independence and impartiality.\" The war between Israel and Hamas militants in Gaza last summer left more than 2,000 people dead. The inquiry will include alleged war crimes committed since June. The International Criminal Court was set up in 2002 to prosecute genocide, crimes against humanity and war crimes. CNN\\'s Vasco Cotovio, Kareem Khadder and Faith Karimi contributed to this report.',\n 'highlights': 'Membership gives the ICC jurisdiction over alleged crimes committed in Palestinian territories since last June . Israel and the United States opposed the move, which could open the door to war crimes investigations against Israelis .',\n 'id': 'f001ec5c4704938247d27a44948eebb37ae98d01'}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:15:01.591935200Z",
     "start_time": "2024-04-22T02:15:01.557933500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "287113"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:15:01.603937100Z",
     "start_time": "2024-04-22T02:15:01.571935500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'article': 'LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won\\'t cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don\\'t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don\\'t think I\\'ll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he\\'ll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I\\'ll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe\\'s earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say \\'kid star goes off the rails,\\'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter\\'s latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer\\'s \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he\\'s legally an adult: \"I just think I\\'m going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.',\n 'highlights': \"Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday . Young actor says he has no plans to fritter his cash away . Radcliffe's earnings from first five Potter films have been held in trust fund .\",\n 'id': '42c027e4ff9730fbb3de84c1af0d2c506e41c3e4'}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:15:01.642931600Z",
     "start_time": "2024-04-22T02:15:01.595935100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'article': 'LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won\\'t cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don\\'t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don\\'t think I\\'ll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he\\'ll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I\\'ll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe\\'s earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say \\'kid star goes off the rails,\\'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter\\'s latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer\\'s \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he\\'s legally an adult: \"I just think I\\'m going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.',\n 'highlights': \"Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday . Young actor says he has no plans to fritter his cash away . Radcliffe's earnings from first five Potter films have been held in trust fund .\",\n 'id': '42c027e4ff9730fbb3de84c1af0d2c506e41c3e4'}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3: Analyze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:15:18.024924700Z",
     "start_time": "2024-04-22T02:15:17.966924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:15:18.895325800Z",
     "start_time": "2024-04-22T02:15:18.717317500Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-small\", max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:15:21.867337300Z",
     "start_time": "2024-04-22T02:15:21.858337700Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_func(examples):\n",
    "    contents = ['Generate summary: \\n' + e for e in examples['article']]\n",
    "    inputs = tokenizer(contents, max_length=1024, truncation=True)\n",
    "    labels = tokenizer(text_target=examples['highlights'], max_length=64, truncation=True)\n",
    "    inputs['labels'] = labels['input_ids']\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:15:28.913633700Z",
     "start_time": "2024-04-22T02:15:23.439130800Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_ds = ds.map(process_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:15:28.938631300Z",
     "start_time": "2024-04-22T02:15:28.915631100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Generate summary: LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won\\'t cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don\\'t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don\\'t think I\\'ll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he\\'ll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I\\'ll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe\\'s earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say \\'kid star goes off the rails,\\'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films. Watch I-Reporter give her review of Potter\\'s latest ». There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer\\'s \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he\\'s legally an adult: \"I just think I\\'m going to be more sort of fair game,\" he told Reuters. E-mail to a friend. Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.</s>'"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_ds['train'][0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:15:29.982407700Z",
     "start_time": "2024-04-22T02:15:29.968404500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday. Young actor says he has no plans to fritter his cash away. Radcliffe's earnings from first five Potter films have been held in trust fund.</s>\""
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_ds['train'][0]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\"Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday . Young actor says he has no plans to fritter his cash away . Radcliffe's earnings from first five Potter films have been held in trust fund .\""
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]['highlights']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T02:15:30.990160200Z",
     "start_time": "2024-04-22T02:15:30.956162500Z"
    }
   },
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step4: Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:15:34.985306700Z",
     "start_time": "2024-04-22T02:15:34.011649600Z"
    }
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google-t5/t5-small\", max_length=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step5: Create evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:15:38.277314500Z",
     "start_time": "2024-04-22T02:15:38.248323500Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rouge import Rouge\n",
    "\n",
    "rouge = Rouge()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:59:20.141246900Z",
     "start_time": "2024-04-22T02:59:20.121248600Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metric(evalPred):\n",
    "    preds, labels = evalPred.predictions, evalPred.label_ids\n",
    "    decode_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decode_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    decode_preds = [\" \".join(p) for p in decode_preds]\n",
    "    decode_labels = [\" \".join(p) for p in decode_labels]\n",
    "    scores = rouge.get_scores(decode_preds, decode_labels, avg=True)\n",
    "    #scores = rouge.get_scores(decode_preds, decode_labels, avg=True)\n",
    "    return {\"rouge-l\": scores['rouge-l']['f']}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step6: Set training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:59:21.649815Z",
     "start_time": "2024-04-22T02:59:21.571779900Z"
    }
   },
   "outputs": [],
   "source": [
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./summary\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=8,\n",
    "    warmup_steps=128,\n",
    "    logging_steps=1024,\n",
    "    logging_dir=\"./logging\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=512,\n",
    "    save_total_limit=3,     # save the last 3 model\n",
    "    metric_for_best_model=\"rouge-l\",\n",
    "    predict_with_generate=True,  # must set True\n",
    "    #load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step7: Create trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:59:22.688644600Z",
     "start_time": "2024-04-22T02:59:22.667649700Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    args=args,\n",
    "    model=model,\n",
    "    train_dataset=tokenized_ds['train'],\n",
    "    eval_dataset=tokenized_ds['test'],\n",
    "    compute_metrics=compute_metric,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step8: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T05:12:36.848849900Z",
     "start_time": "2024-04-22T02:59:24.488491900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='257' max='13458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  257/13458 15:22 < 13:16:04, 0.28 it/s, Epoch 0.06/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>256</td>\n      <td>1.919900</td>\n      <td>1.767691</td>\n      <td>0.768248</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='513' max='13458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  513/13458 1:00:11 < 25:24:37, 0.14 it/s, Epoch 0.11/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>256</td>\n      <td>1.919900</td>\n      <td>1.767691</td>\n      <td>0.768248</td>\n    </tr>\n    <tr>\n      <td>512</td>\n      <td>1.922800</td>\n      <td>1.744241</td>\n      <td>0.769261</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='769' max='13458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  769/13458 1:45:03 < 28:58:03, 0.12 it/s, Epoch 0.17/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>256</td>\n      <td>1.919900</td>\n      <td>1.767691</td>\n      <td>0.768248</td>\n    </tr>\n    <tr>\n      <td>512</td>\n      <td>1.922800</td>\n      <td>1.744241</td>\n      <td>0.769261</td>\n    </tr>\n    <tr>\n      <td>768</td>\n      <td>1.914500</td>\n      <td>1.736634</td>\n      <td>0.770397</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='777' max='13458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  777/13458 2:13:04 < 36:17:20, 0.10 it/s, Epoch 0.17/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>256</td>\n      <td>1.919900</td>\n      <td>1.767691</td>\n      <td>0.768248</td>\n    </tr>\n    <tr>\n      <td>512</td>\n      <td>1.922800</td>\n      <td>1.744241</td>\n      <td>0.769261</td>\n    </tr>\n    <tr>\n      <td>768</td>\n      <td>1.914500</td>\n      <td>1.736634</td>\n      <td>0.770397</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\transformers\\trainer.py:1780\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   1778\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[0;32m   1779\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1780\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1781\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1782\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1783\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1784\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1785\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\transformers\\trainer.py:2118\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   2115\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_step_begin(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[0;32m   2117\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39maccumulate(model):\n\u001B[1;32m-> 2118\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2120\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   2121\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[0;32m   2122\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[0;32m   2123\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[0;32m   2124\u001B[0m ):\n\u001B[0;32m   2125\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[0;32m   2126\u001B[0m     tr_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\transformers\\trainer.py:3045\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[1;34m(self, model, inputs)\u001B[0m\n\u001B[0;32m   3043\u001B[0m         scaled_loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m   3044\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 3045\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maccelerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3047\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\u001B[38;5;241m.\u001B[39mdetach() \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mgradient_accumulation_steps\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\accelerate\\accelerator.py:2013\u001B[0m, in \u001B[0;36mAccelerator.backward\u001B[1;34m(self, loss, **kwargs)\u001B[0m\n\u001B[0;32m   2011\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscaler\u001B[38;5;241m.\u001B[39mscale(loss)\u001B[38;5;241m.\u001B[39mbackward(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   2012\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2013\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\torch\\_tensor.py:522\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    512\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    513\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    514\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    515\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    520\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    521\u001B[0m     )\n\u001B[1;32m--> 522\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    524\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\torch\\autograd\\__init__.py:266\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    261\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    263\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    264\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 266\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    274\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manchester United thrashes Tottenham Hotspur 3-0 . Wayne Rooney celebrates his goal by pretending to be knocked out . Chelsea held 1-1 at home but extends EPL lead at top to six points . Gareth Bale scores twice as Real Madrid keeps pace in La Liga .\n",
      "----------------------------------\n",
      "Wayne Rooney scores first half goals to give Tottenham Hotspur 3-0 win . Tottenham are seventh, six points adrift of the top four . Everton ease relegation fears with 3-0 win over Newcastle .\n",
      "----------------------------------\n",
      "\n",
      " Rouge-L between label and generate summary with t5 model is  {'r': 0.32142857142857145, 'p': 0.21951219512195122, 'f': 0.2608695603948751}\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline('text2text-generation', model=model, tokenizer=tokenizer, device=0)\n",
    "text = ds['validation'][200]['article']\n",
    "target = ds['validation'][200]['highlights']\n",
    "print(target)\n",
    "print(\"----------------------------------\\n\")\n",
    "pip_res = pipe(\"Generate summary:\\n\" + text, max_length = 64)\n",
    "t5_summary = pip_res[0]['generated_text']\n",
    "print(t5_summary)\n",
    "print(\"----------------------------------\\n\")\n",
    "print(\" Rouge-L between label and generate summary with t5 model is \", rouge.get_scores(target, t5_summary)[0]['rouge-l'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T22:49:58.533336100Z",
     "start_time": "2024-04-20T22:49:57.631336600Z"
    }
   },
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step8.5: Retrain model if needed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (935 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded...\n",
      "\n",
      "Manchester United thrashes Tottenham Hotspur 3-0 . Wayne Rooney celebrates his goal by pretending to be knocked out . Chelsea held 1-1 at home but extends EPL lead at top to six points . Gareth Bale scores twice as Real Madrid keeps pace in La Liga .\n",
      "----------------------------------\n",
      "Wayne Rooney scores first half goals to give Tottenham Hotspur 3-0 win . Marouane Fellaini, Michael Carrick and Rooney score . Everton ease relegation fears with 3-0 win over Newcastle .\n",
      "----------------------------------\n",
      "\n",
      " Rouge-L between label and generate summary with t5 model is  {'r': 0.28, 'p': 0.17073170731707318, 'f': 0.2121212074150598}\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./summary/last-checkpoint-3072\")\n",
    "print(\"Model weights loaded...\\n\")\n",
    "\n",
    "pipe = pipeline('text2text-generation', model=model, tokenizer=tokenizer, device=0)\n",
    "text = ds['validation'][200]['article']\n",
    "target = ds['validation'][200]['highlights']\n",
    "print(target)\n",
    "print(\"----------------------------------\\n\")\n",
    "pip_res = pipe(\"Generate summary:\\n\" + text, max_length = 64)\n",
    "t5_summary = pip_res[0]['generated_text']\n",
    "print(t5_summary)\n",
    "print(\"----------------------------------\\n\")\n",
    "print(\" Rouge-L between label and generate summary with t5 model is \", rouge.get_scores(target, t5_summary)[0]['rouge-l'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T00:03:25.818811600Z",
     "start_time": "2024-04-22T00:03:13.672416100Z"
    }
   },
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'r': 0.41089488479762454, 'p': 0.3141787777530955, 'f': 0.346684883166558}"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validations = ds['validation']\n",
    "texts: list[str] = validations['article']\n",
    "labels: list[str] = validations['highlights']\n",
    "t5_summaries : list[str] = [pipe(each, max_length = 64)[0]['generated_text'] for each in texts]\n",
    "rouge.get_scores(labels, t5_summaries, avg=True)['rouge-l']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T02:02:36.357590500Z",
     "start_time": "2024-04-20T00:18:19.879318200Z"
    }
   },
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google-t5/t5-base and revision 686f1db (https://huggingface.co/google-t5/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a055b2c8261240a08963ef41f6b09011"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\ML2\\lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--google-t5--t5-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "16f763de31ec4719b4c0185481aa7b38"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ed13ee2bf0e84c70a40eb3d4f47b3245"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f7ba3b99ff2044ff9102a10b999b3006"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "51424c85ec3249a9a917a8721dba4102"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\ML2\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:171: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on google-t5/t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\envs\\ML2\\lib\\site-packages\\transformers\\generation\\utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Prompt: Once upon a time, there was a king who ruled over a prosperous kingdom.\n",
      "Generated Text: [{'generated_text': 'a king who ruled over a prosperous kingdom. there was a'}]\n",
      "\n",
      "Input Prompt: In a galaxy far, far away, a young Jedi embarked on a journey to defeat the Sith.\n",
      "Generated Text: [{'generated_text': 'a galaxy far, far away., far away. A Jedi. A Jedi'}]\n",
      "\n",
      "Input Prompt: The scientist conducted an experiment that would change the course of human history.\n",
      "Generated Text: [{'generated_text': 'a scientist who conducted an experiment that would change the course of human history.'}]\n"
     ]
    }
   ],
   "source": [
    "text_generator = pipeline(\"text2text-generation\")\n",
    "\n",
    "# List of input prompts\n",
    "input_prompts = [\n",
    "    \"Once upon a time, there was a king who ruled over a prosperous kingdom.\",\n",
    "    \"In a galaxy far, far away, a young Jedi embarked on a journey to defeat the Sith.\",\n",
    "    \"The scientist conducted an experiment that would change the course of human history.\"\n",
    "]\n",
    "\n",
    "# Generate results for each input prompt\n",
    "results = [text_generator(prompt) for prompt in input_prompts]\n",
    "\n",
    "# Print results\n",
    "for input_prompt, result in zip(input_prompts, results):\n",
    "    print(\"Input Prompt:\", input_prompt)\n",
    "    print(\"Generated Text:\", result)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:05:01.580361400Z",
     "start_time": "2024-04-20T00:04:44.465338300Z"
    }
   },
   "execution_count": 70
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step9: Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "from heapq import nlargest\n",
    "from datasets import load_dataset\n",
    "from rouge import Rouge\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "stopwords = list(STOP_WORDS)\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T15:21:19.129015900Z",
     "start_time": "2024-04-19T15:21:19.125014500Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def select_main_sentence(text, punctuation, nlp):\n",
    "    summary_length = 3\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]\n",
    "    punctuation = punctuation + '\\n'\n",
    "    sentence_tokens = [sent for sent in doc.sents]\n",
    "    \n",
    "    word_frequencies = {}\n",
    "    for word in doc:\n",
    "        if word.text.lower() not in stopwords:\n",
    "            if word.text.lower() not in punctuation:\n",
    "                if word.text not in word_frequencies.keys():\n",
    "                    word_frequencies[word.text] = 1\n",
    "                else:\n",
    "                    word_frequencies[word.text] += 1\n",
    "\n",
    "    sentence_scores = {}\n",
    "    for sent in sentence_tokens:\n",
    "        for word in sent:\n",
    "            if word.text.lower() in word_frequencies.keys():\n",
    "                if sent not in sentence_scores.keys():\n",
    "                    sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
    "                else:\n",
    "                    sentence_scores[sent] += word_frequencies[word.text.lower()]\n",
    "         \n",
    "    summary = nlargest(summary_length, sentence_scores, key = sentence_scores.get)\n",
    "    return summary"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-19T15:21:19.128016500Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T15:21:19.131016800Z",
     "start_time": "2024-04-19T15:21:19.130017600Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"\\n----------------------------article---------------------------------------\\n\")\n",
    "text = ds['validation'][1400]['article']\n",
    "print(text)\n",
    "print(\"\\n----------------------------label---------------------------------------\\n\")\n",
    "target = ds['validation'][1400]['highlights']\n",
    "print(target)\n",
    "print(\"\\n----------------------------generate summary---------------------------------------\")\n",
    "summary = select_main_sentence(text, punctuation, nlp)\n",
    "generate_summary = \"\"\n",
    "for each in summary:\n",
    "    generate_summary = generate_summary + str(each)\n",
    "print(generate_summary)\n",
    "print(\" Rouge-L: \", rouge.get_scores(target, generate_summary)[0]['rouge-l'])\n",
    "\n",
    "print(\"\\n----------------------------generate summary t5 model---------------------------------------\")\n",
    "pip_res = pipe(\"Generate summary:\\n\" + text, max_length = 64)\n",
    "t5_summary = pip_res[0]['generated_text']\n",
    "print(t5_summary)\n",
    "print(\" Rouge-L between label and generate summary with t5 model is \", rouge.get_scores(target, t5_summary)[0]['rouge-l'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-19T15:21:19.132016700Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T17:10:38.674174700Z",
     "start_time": "2024-04-19T17:10:38.670171100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
